{"pages":[{"title":"","text":"申请友链须知 原则上只和技术类博客交换，但不包括含有和色情、暴力、政治敏感的网站。 不和剽窃、侵权、无诚信的网站交换，优先和具有原创作品的网站交换。 申请请提供：站点名称、站点链接、站点描述、logo或头像（不要设置防盗链）。 排名不分先后，刷新后重排，更新信息后请留言告知。 会定期清理很久很久不更新的、不符合要求的友链，不再另行通知。 本站不存储友链图片，如果友链图片换了无法更新。图片裂了的会替换成默认图，需要更换的请留言告知。 本站友链信息如下，申请友链前请先添加本站信息： 网站图标：https://hellosyl.github.io/img/avatar.png 网站名称：hellosyl 网站地址：https://hellosyl.github.io 网站简介：后端开发，技术分享 加载中，稍等几秒...","link":"/friend/index.html"},{"title":"","text":"来而不往非礼也畅所欲言，有留必应","link":"/message/index.html"},{"title":"","text":"个人简介 分享主题作者和我都很喜欢的老罗的一段话： “每一个生命来到世间都注定改变世界，别无选择。要么变得好一点，要么变得坏一点。你如果走进社会为了生存为了什么不要脸的理由，变成了一个恶心的成年人社会中的一员，那你就把这个世界变得恶心了一点点。如果你一生刚正不阿，如果你一生耿直，没有做任何恶心的事情，没做对别人有害的事情，一辈子拼了老命勉强把自己身边的几个人照顾好了，没有成名没有发财，没有成就伟大的事业，然后耿着脖子一生正直，到了七八十岁耿着脖子去世了。你这一生是不是没有改变世界？你还是改变世界了，你把这个世界变得美好了一点点。因为世界上又多了一个好人。” 善恶终有报，天道好轮回。不信抬头看，苍天饶过谁。无论何时何地，我们都要保持一颗积极乐观、善良感恩的心。但行好事莫问前程，永远年轻，永远热内盈眶，永远保持正能量。💪💪💪💪💪💪冲鸭！！！！ -&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;个人信息：通信工程专业从事JAVA后端开发坚信代码改变世界 博客信息 网站采用的Amazing主题 追求尽可能的简洁，清晰，易用。 感谢主题作者的分享。 本站推荐索引 技术知识点 Java并发知识点 法律法规 法律法规数据库 中华人民共和国国旗法 中华人民共和国宪法 中华人民共和国消费者权益保护法 中华人民共和国刑事诉讼法 中华人民共和国婚姻法 中华人名共和国网络安全法 中华人民共和国劳动法 其他 计划2020计划 2019.12.31 2020-GOALS 跑两三场马拉松 2019计划 2018.12.31/21:59:00-&gt;更新于2019.12.31 2019-GOALS 购买的专业书籍至少看完一遍（并发、重构、设计模式…）-&gt; 95% 额外： 追了很多剧 总结： 有优点有缺点，没坚持下来的还是太多，追了太多剧。以后多学习，多思考！ 时间轴记录","link":"/about/index.html"},{"title":"音乐歌单收藏","text":"温馨提示：选择喜欢的音乐双击播放，由于版权原因部分不能播放。如果喜欢歌单收藏一下，去网易云都能播放哟！","link":"/music/index.html"},{"title":"","text":"唐艺昕 李沁 李一桐 gakki 图片搜集于互联网，侵权请留言，马上处理😊。","link":"/album/index.html"},{"title":"","text":"&nbsp;&nbsp;听听音乐 音乐播放器由mePlayer提供，布局参照网友博客所作，感谢作者的辛勤付出。更多音乐分享请查看歌单。 &nbsp;&nbsp;看看视频 ->点击以下条目开始播放视频,向下滑动查看更多","link":"/media/index.html"},{"title":"","text":"碎碎念 tips：github登录后按时间正序查看、可点赞加❤️、本插件地址..「+99次查看」 碎碎念加载中，请稍等... $.getScript(\"/js/gitalk_self.min.js\", function () { var gitalk = new Gitalk({ clientID: 'b57588205e5c0f76a733', clientSecret: '7d5b4255e5babcbca5471ec05f79c63373cae2da', id: '666666', repo: 'hellosyl.github.io', owner: 'hellosyl', admin: \"hellosyl\", createIssueManually: true, distractionFreeMode: false }); gitalk.render('comment-container1'); });","link":"/self-talking/index.html"}],"posts":[{"title":"Hello World","text":"嗨，请准确无误地输入密码查看哟！ 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","link":"/2020/09/30/hello-world/"},{"title":"test","text":"这是测试…. 一、…. 二、 …. 三、","link":"/2020/10/01/online-utils/"},{"title":"TCP与UDP","text":"【尚未完结】 一、互联网的基石1、网络协议及模型计算机与网络设备要相互通信，双方就必须基于相同的方法。比如，如何探测到通信目标、由哪一边先发起通信、使用哪种语言进行通信、怎样结束通信等规则都需要事先确定。不同的硬件、操作系统之间的通信，所有的这一切都需要一种规则。而我们就把这种规则称为协议（protocol）。网络协议有很多，按照功能不同，分工不同，人们人为的将其进行了分层，更便于理解。例如OSI七层模型，TCP/IP四层模型。实际上这个七层四层是不存在的，只是人为的划分的概念，区分出来的目的只是让你明白哪一层是干什么用的。 OSI：开放式系统互联通信参考模型（英语：Open System Interconnection Reference Model，缩写为 OSI），简称为 OSI 模型（OSI model），一种概念模型，由国际标准化组织提出，一个试图使各种计算机在世界范围内互连为网络的标准框架。定义于ISO/IEC 7498-1。 TCP/IP：（Transmission Control Protocol/Internet Protocol，传输控制协议/网际协议）是指能够在多个不同网络间实现信息传输的协议簇。 TCP、UDP、IP、FTP、HTTP、ICMP、SMTP 等都属于 TCP/IP 族内的协议， 只是因为在 TCP/IP 协议中 TCP 协议和 IP 协议最具代表性，所以被称为 TCP/IP 协议。这些协议可以划分为四层，分别为链路层、网络层、传输层和应用层。 2、TCP和UDP下图展示了分层模型： 如图所示，TCP和UDP都是传输层协议，在《OSI七层网络协议详解》一文中详细的讲解了各个分层在网络传输中的作用及原理。 传输层提供逻辑连接的建立、传输层寻址、数据传输、传输连接释放、流量控制、拥塞控制、多路复用和解复用、崩溃恢复等服务。 二、TCP1、TCP的概念 当一台计算机想要与另一台计算机通讯时，两台计算机之间的通信需要畅通且可靠，这样才能保证正确收发数据。例如，当你想查看网页或查看电子邮件时，希望完整且按顺序查看网页，而不丢失任何内容。当你下载文件时，希望获得的是完整的文件，而不仅仅是文件的一部分，因为如果数据丢失或乱序，都不是你希望得到的结果，于是就用到了 TCP。 TCP协议全称是（Transmission Control Protocol）传输控制协议是一种面向连接的、可靠的、全双工通信的、基于字节流的传输层通信协议。 2、TCP报文结构 报文整体 TCP首部 tcp flags 状态控制码，占 6 比特位，含义如下： URG：紧急比特（urgent），当 URG＝1 时，表明紧急指针字段有效，代表该封包为紧急封包。它告诉系统此报文段中有紧急数据，应尽快传送(相当于高优先级的数据)， 且上图中的 Urgent Pointer 字段也会被启用。 ACK：确认比特（Acknowledge）。只有当 ACK＝1 时确认号字段才有效，代表这个封包为确认封包。当 ACK＝0 时，确认号无效。 PSH：（Push function）若为 1 时，代表要求对方（接收端）立即传送缓冲区内的其他对应封包，而无需等缓冲满了才送。 RST：复位比特(Reset)，当 RST＝1 时，表明 TCP 连接中出现严重差错（如由于主机崩溃或其他原因），必须释放连接，然后再重新建立运输连接。 SYN：同步比特(Synchronous)，SYN 置为 1，就表示这是一个连接请求或连接接受报文，通常带有 SYN 标志的封包表示『主动』要连接到对方的意思。 FIN：终止比特(Final)，用来释放一个连接。当 FIN＝1 时，表明此报文段的发送端的数据已发送完毕，并要求释放传输连接。 序列号（小写单词是序列号，大写单词是状态控制码非0及1） 序号seq：占4个字节，用来标记数据段的顺序，TCP把连接中发送的所有数据字节都编上一个序号，第一个字节的编号由本地随机产生；给字节编上序号后，就给每一个报文段指派一个序号；序列号seq就是这个报文段中的第一个字节的数据编号。 确认号ack：占4个字节，期待收到对方下一个报文段的第一个数据字节的序号；序列号表示报文段携带数据的第一个字节的编号；而确认号指的是期望接收到下一个字节的编号；因此当前报文段最后一个字节的编号+1即为确认号。 3、TCP的连接过程 TCP 是面向连接的，无论哪一方向另一方发送数据之前，都必须先在双方之间建立一条连接。在 TCP/IP 协议中，TCP 协议提供可靠的连接服务，连接是通过三次握手进行初始化的。三次握手的目的是同步连接双方的序列号和确认号并交换 TCP 窗口大小信息。这就是面试中经常会被问到的 TCP 三次握手。只是了解 TCP 三次握手的概念，对你获得一份工作是没有任何帮助的，你需要去了解 TCP 三次握手中的一些细节。先来看图说话。 3.1 TCP 三次握手 第一次握手：建立连接。客户端发送连接请求报文段，将 SYN 位置为1，seq（sequence number）为 x；然后，客户端进入 SYN_SENT 状态，等待服务器的确认； 第二次握手：服务器收到 SYN 报文段。服务器收到客户端的 SYN 报文段，需要对这个 SYN 报文段进行确认，设置 acknowledgment number 为 x+1(sequence number+1)；同时，自己自己还要发送 SYN 请求信息，将 SYN 位置为1，sequence number为y；服务器端将上述所有信息放到一个报文段（即 SYN+ACK 报文段）中，一并发送给客户端，此时服务器进入 SYN_RECV 状态； 第三次握手：客户端收到服务器的 SYN+ACK 报文段。然后将 acknowledgment number 设置为 y+1，向服务器发送 ACK 报文段，这个报文段发送完毕以后，客户端和服务器端都进入 ESTABLISHED 状态，完成 TCP 三次握手。 3.2 TCP 四次挥手 第一次分手：主机1（可以使客户端，也可以是服务器端），设置 sequence number 和 acknowledgment number，向主机2发送一个FIN报文段；此时，主机1进入 FIN_WAIT_1 状态；这表示主机1没有数据要发送给主机2了； 第二次分手：主机2收到了主机1发送的FIN报文段，向主机1回一个 ACK 报文段，acknowledgment number 为 sequence number 加1；主机1进入FIN_WAIT_2状态；主机2告诉主机1，我“同意”你的关闭请求； 第三次分手：主机2向主机1发送FIN报文段，请求关闭连接，同时主机2进入LAST_ACK状态； 第四次分手：主机1收到主机2发送的 FIN 报文段，向主机2发送 ACK 报文段，然后主机1进入 TIME_WAIT 状态；主机2收到主机1的 ACK 报文段以后，就关闭连接；此时，主机1等待2MSL后依然没有收到回复，则证明 Server 端已正常关闭，那好，主机1也可以关闭连接了。 3.3 TCP 为什么要三次握手 为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误。 已失效的连接请求报文段的产生在这样一种情况下：client 发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达 server。本来这是一个早已失效的报文段。但 server 收到此失效的连接请求报文段后，就误认为是 client 再次发出的一个新的连接请求。于是就向 client 发出确认报文段，同意建立连接。假设不采用三次握手，那么只要 server 发出确认，新的连接就建立了。由于现在 client 并没有发出建立连接的请求，因此不会理睬 server 的确认，也不会向 server 发送数据。但 server 却以为新的运输连接已经建立，并一直等待 client 发来数据。这样，server 的很多资源就白白浪费掉了。采用三次握手的办法可以防止上述现象发生。例如刚才那种情况，client 不会向 server 的确认发出确认。server 由于收不到确认，就知道 client 并没有要求建立连接。 3.4 TCP 为什么要四次挥手 那四次分手又是为何呢？TCP协议是一种面向连接的、可靠的、基于字节流的运输层通信协议。TCP是全双工模式，这就意味着，当主机1发出FIN报文段时，只是表示主机1已经没有数据要发送了，主机1告诉主机2，它的数据已经全部发送完毕了；但是，这个时候主机1还是可以接受来自主机2的数据；当主机2返回ACK报文段时，表示它已经知道主机1没有数据发送了，但是主机2还是可以发送数据到主机1的；当主机2也发送了FIN报文段时，这个时候就表示主机2也没有数据要发送了，就会告诉主机1，我也没有数据要发送了，之后彼此就会愉快的中断这次TCP连接。如果要正确的理解四次分手的原理，就需要了解四次分手过程中的状态变化。 FIN_WAIT_1: 这个状态要好好解释一下，其实FIN_WAIT_1和FIN_WAIT_2状态的真正含义都是表示等待对方的FIN报文。而这两种状态的区别是：FIN_WAIT_1状态实际上是当SOCKET在ESTABLISHED状态时，它想主动关闭连接，向对方发送了FIN报文，此时该SOCKET即进入到FIN_WAIT_1状态。而当对方回应ACK报文后，则进入到FIN_WAIT_2状态，当然在实际的正常情况下，无论对方何种情况下，都应该马上回应ACK报文，所以FIN_WAIT_1状态一般是比较难见到的，而FIN_WAIT_2状态还有时常常可以用netstat看到。（主动方）FIN_WAIT_2：上面已经详细解释了这种状态，实际上FIN_WAIT_2状态下的SOCKET，表示半连接，也即有一方要求close连接，但另外还告诉对方，我暂时还有点数据需要传送给你(ACK信息)，稍后再关闭连接。（主动方）CLOSE_WAIT：这种状态的含义其实是表示在等待关闭。怎么理解呢？当对方close一个SOCKET后发送FIN报文给自己，你系统毫无疑问地会回应一个ACK报文给对方，此时则进入到CLOSE_WAIT状态。接下来呢，实际上你真正需要考虑的事情是察看你是否还有数据发送给对方，如果没有的话，那么你也就可以 close这个SOCKET，发送FIN报文给对方，也即关闭连接。所以你在CLOSE_WAIT状态下，需要完成的事情是等待你去关闭连接。（被动方）LAST_ACK: 这个状态还是比较容易好理解的，它是被动关闭一方在发送FIN报文后，最后等待对方的ACK报文。当收到ACK报文后，也即可以进入到CLOSED可用状态了。（被动方）TIME_WAIT: 表示收到了对方的FIN报文，并发送出了ACK报文，就等2MSL后即可回到CLOSED可用状态了。如果FINWAIT1状态下，收到了对方同时带FIN标志和ACK标志的报文时，可以直接进入到TIME_WAIT状态，而无须经过FIN_WAIT_2状态。（主动方）CLOSED: 表示连接中断。 三、UDP四、TCP与UDP简单对比1、TCP的概念 TCP在传输数据之前必须先建立连接，数据传输结束后要释放连接。 每一条TCP连接只能有2个端点，故TCP不提供广播或多播服务。 TCP提供可靠交互，通过TCP连接传输的数据，无差错、不丢失、不重复、并且按序到达。 TCP是面向字节流的。虽然应用进程和TCP的交互是一次一个数据块(大小不等），但TCP把应用程序交下来的数据看成仅仅是一连串的无结构的字节流。TCP并不知道所传输的字节流的含义。 2、UDP的概念 UDP（User Datagram Protocol）用户数据报协议UDP是一种无连接的，尽最大努力交付的，基于报文的端到端的传输层通信协议。 UDP，在发送数据之前不需要建立连接。 UDP不保证可靠交互，主机不需要位置复杂的连接状态。 UDP是面向报文的。UDP对应用层交下来的报文，既不合并，也不拆分，而是保留这些报文的的边界，即应用层交给UDP多长的报文，UDP就照样发送，即一次发送一个报文。在接收端，UDP一次交付一个完整的报文。 UDP没有拥塞控制，网络出现的拥塞不会使源主机的发送速率降低。 UDP支持一对一、一对多、多对一和多对多的交互通信。 UDP的首部开销小，只有8个字节，比TCP的20个字节的首部要短。 3、区别 TCP协议面向连接，UDP协议面向非连接。 TCP协议传输速度慢，UDP协议传输速度快。 TCP协议保证数据顺序，UDP协议不保证。 TCP协议保证数据正确性，UDP协议可能丢包。 TCP协议对系统资源要求多，UDP协议要求少。 4、使用情况 TCP协议适用于对效率要求相对低，但对准确性要求相对高的场景下，或者是有一种连接概念的场景下。 而UDP协议适用于对效率要求相对高，对准确性要求相对低的场景。","link":"/2020/10/23/computer_network/tcp-udp/"},{"title":"HashMap 源码翻译","text":"基于JDK1.8 版权声明>folded12345678910111213141516171819/* * Copyright (c) 1997, 2013, Oracle and/or its affiliates. All rights reserved. * ORACLE PROPRIETARY/CONFIDENTIAL. Use is subject to license terms. * * 版权所有（c）1997、2013，Oracle 和/或 其分支机构。 版权所有。 * Oracle 专有/机密。 使用须遵守许可条款。 * */package java.util;import java.io.IOException;import java.io.InvalidObjectException;import java.io.Serializable;import java.lang.reflect.ParameterizedType;import java.lang.reflect.Type;import java.util.function.BiConsumer;import java.util.function.BiFunction;import java.util.function.Consumer;import java.util.function.Function; 类说明>folded123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129/** * Hash table based implementation of the &lt;tt&gt;Map&lt;/tt&gt; interface. This * implementation provides all of the optional map operations, and permits * &lt;tt&gt;null&lt;/tt&gt; values and the &lt;tt&gt;null&lt;/tt&gt; key. (The &lt;tt&gt;HashMap&lt;/tt&gt; * class is roughly equivalent to &lt;tt&gt;Hashtable&lt;/tt&gt;, except that it is * unsynchronized and permits nulls.) This class makes no guarantees as to * the order of the map; in particular, it does not guarantee that the order * will remain constant over time. * 基于哈希表的Map接口的实现。此实现提供所有可选的map操作，并[允许null值和null键]。 * （HashMap类与Hashtable大致等效，不同之处在于它是不同步的，并且允许为null。） * 此类不保证map元素的顺序。特别是，它不能保证顺序会随着时间的推移保持恒定。 * * &lt;p&gt;This implementation provides constant-time performance for the basic * operations (&lt;tt&gt;get&lt;/tt&gt; and &lt;tt&gt;put&lt;/tt&gt;), assuming the hash function * disperses the elements properly among the buckets. Iteration over * collection views requires time proportional to the &quot;capacity&quot; of the * &lt;tt&gt;HashMap&lt;/tt&gt; instance (the number of buckets) plus its size (the number * of key-value mappings). Thus, it's very important not to set the initial * capacity too high (or the load factor too low) if iteration performance is * important. * 假设哈希函数将元素正确的分散在存储桶中，则此实现为基本操作（get和put）提供恒定时间的性能。 * 集合视图迭代所需的时间与HashMap实例的“容量”（存储桶数）以及其大小（键-值映射数）成正比。 * 因此，如果迭代性能很重要，则不要将初始容量设置得过高（或负载因子过低），这一点非常重要。 * * &lt;p&gt;An instance of &lt;tt&gt;HashMap&lt;/tt&gt; has two parameters that affect its * performance: &lt;i&gt;initial capacity&lt;/i&gt; and &lt;i&gt;load factor&lt;/i&gt;. The * &lt;i&gt;capacity&lt;/i&gt; is the number of buckets in the hash table, and the initial * capacity is simply the capacity at the time the hash table is created. The * &lt;i&gt;load factor&lt;/i&gt; is a measure of how full the hash table is allowed to * get before its capacity is automatically increased. When the number of * entries in the hash table exceeds the product of the load factor and the * current capacity, the hash table is &lt;i&gt;rehashed&lt;/i&gt; (that is, internal data * structures are rebuilt) so that the hash table has approximately twice the * number of buckets. * HashMap的实例具有两个影响其性能的参数：初始容量和负载因子。 * 容量是哈希表中能存储的桶的数量，初始容量只是创建哈希表时的容量。 * 负载因子是哈希表的容量自动增加之前允许其填充的填满程度的度量。 * 当哈希表中的条目数超过负载因子和当前容量的乘积时，哈希表将被重新哈希（即，内部数据结构将被重建），因此哈希表的容量大约为桶数的两倍。 * * &lt;p&gt;As a general rule, the default load factor (.75) offers a good * tradeoff between time and space costs. Higher values decrease the * space overhead but increase the lookup cost (reflected in most of * the operations of the &lt;tt&gt;HashMap&lt;/tt&gt; class, including * &lt;tt&gt;get&lt;/tt&gt; and &lt;tt&gt;put&lt;/tt&gt;). The expected number of entries in * the map and its load factor should be taken into account when * setting its initial capacity, so as to minimize the number of * rehash operations. If the initial capacity is greater than the * maximum number of entries divided by the load factor, no rehash * operations will ever occur. * 通常，默认负载因子（0.75）在时间和空间成本之间提供了很好的折中。 * 较高的值会减少空间开销，但会增加查找成本（在HashMap类的大多数操作中都得到体现，包括get和put）。 * 设置其初始容量时，应考虑映射中的预期条目数及其负载因子，以最大程度地减少重新哈希操作的次数。 * 如果初始容量大于最大条目数除以负载因子，则将不会进行任何哈希操作。 * （即 初始容量 * 负载因子 &gt; 最大条目数），这里最大条目数指预期要存储的最大桶子数 * * &lt;p&gt;If many mappings are to be stored in a &lt;tt&gt;HashMap&lt;/tt&gt; * instance, creating it with a sufficiently large capacity will allow * the mappings to be stored more efficiently than letting it perform * automatic rehashing as needed to grow the table. Note that using * many keys with the same {@code hashCode()} is a sure way to slow * down performance of any hash table. To ameliorate impact, when keys * are {@link Comparable}, this class may use comparison order among * keys to help break ties. * 如果将许多映射存储在HashMap实例中，则创建具有足够大容量的映射将比让其根据需要通过自动重新哈希处理来增长表会更有效地存储映射。 * 请注意，使用许多具有相同hashCode()值的键是降低任何哈希表性能的肯定方法。 * 为了改善影响，当键为Comparable类型时，此类可以使用键之间的比较顺序来帮助打破关系。 * * &lt;p&gt;&lt;strong&gt;Note that this implementation is not synchronized.&lt;/strong&gt; * If multiple threads access a hash map concurrently, and at least one of * the threads modifies the map structurally, it &lt;i&gt;must&lt;/i&gt; be * synchronized externally. (A structural modification is any operation * that adds or deletes one or more mappings; merely changing the value * associated with a key that an instance already contains is not a * structural modification.) This is typically accomplished by * synchronizing on some object that naturally encapsulates the map. * 请注意，此实现未同步。 如果多个线程同时访问哈希映射，并且至少一个线程在结构上修改了该映射，则必须在外部进行同步。 * （结构修改是添加或删除一个或多个映射的任何操作；仅更改与实例已经包含的键相关联的值不是结构修改。） * 通常可以通过在封装了map的某个对象上进行同步来实现。 * * If no such object exists, the map should be &quot;wrapped&quot; using the * {@link Collections#synchronizedMap Collections.synchronizedMap} * method. This is best done at creation time, to prevent accidental * unsynchronized access to the map:&lt;pre&gt; * Map m = Collections.synchronizedMap(new HashMap(...));&lt;/pre&gt; * 如果不存在这样的对象，则应使用Collections.synchronizedMap方法“包装”map。 * 最好在创建时完成此操作，以防止意外不同步地访问map： * Map m = Collections.synchronizedMap(new HashMap(...)); * * &lt;p&gt;The iterators returned by all of this class's &quot;collection view methods&quot; * are &lt;i&gt;fail-fast&lt;/i&gt;: if the map is structurally modified at any time after * the iterator is created, in any way except through the iterator's own * &lt;tt&gt;remove&lt;/tt&gt; method, the iterator will throw a * {@link ConcurrentModificationException}. Thus, in the face of concurrent * modification, the iterator fails quickly and cleanly, rather than risking * arbitrary, non-deterministic behavior at an undetermined time in the * future. * 此类的所有“集合视图方法”返回的迭代器都是“fail-fast”（快速失败机制）的：如果在创建迭代器后的任何时间以任何方式对映射进行结构修改， * 则除了通过迭代器自己的remove方法之外，迭代器都会抛出ConcurrentModificationException。 * 因此，面对并发修改，迭代器将快速而干净地失败，而不是冒着在未来不确定的时间冒任何不确定行为的风险。 * * &lt;p&gt;Note that the fail-fast behavior of an iterator cannot be guaranteed * as it is, generally speaking, impossible to make any hard guarantees in the * presence of unsynchronized concurrent modification. Fail-fast iterators * throw &lt;tt&gt;ConcurrentModificationException&lt;/tt&gt; on a best-effort basis. * Therefore, it would be wrong to write a program that depended on this * exception for its correctness: &lt;i&gt;the fail-fast behavior of iterators * should be used only to detect bugs.&lt;/i&gt; * 注意，不能保证迭代器的快速失败行为，因为通常来说，在存在不同步的并发修改的情况下，不可能做出任何严格的保证。 * 快速失败的迭代器会尽最大努力抛出ConcurrentModificationException。因此，编写依赖于此异常的程序的正确性是错误的：迭代器的快速失败行为应仅用于检测错误。 * * &lt;p&gt;This class is a member of the * &lt;a href=&quot;{@docRoot}/../technotes/guides/collections/index.html&quot;&gt; * Java Collections Framework&lt;/a&gt;. * 此类是Java Collections Framework的成员。 * * @param &lt;K&gt; the type of keys maintained by this map | 这是map维护的键的类型 * @param &lt;V&gt; the type of mapped values | 这是映射的值的类型 * * @author Doug Lea * @author Josh Bloch * @author Arthur van Hoff * @author Neal Gafter * @see Object#hashCode() * @see Collection * @see Map * @see TreeMap * @see Hashtable * @since 1.2 */ 类主体实现说明>folded123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable { private static final long serialVersionUID = 362498820763181265L; /* * Implementation notes. * * This map usually acts as a binned (bucketed) hash table, but * when bins get too large, they are transformed into bins of * TreeNodes, each structured similarly to those in * java.util.TreeMap. Most methods try to use normal bins, but * relay to TreeNode methods when applicable (simply by checking * instanceof a node). Bins of TreeNodes may be traversed and * used like any others, but additionally support faster lookup * when overpopulated. However, since the vast majority of bins in * normal use are not overpopulated, checking for existence of * tree bins may be delayed in the course of table methods. * 该map通常用作装箱（存储桶）的哈希表，但是当桶子太大时，它们将转换为TreeNodes的树形结构的桶，每个桶的结构与java.util.TreeMap中的相似。 * 大多数方法尝试使用普通的箱，但是在适用时转接到TreeNode方法（只需通过检查 instanceof node）。 * TreeNodes的树形桶可以像其他任何遍历一样使用，而且过多时还支持更快的查找。 * 但是，由于正常使用中的绝大多数时候存储桶都没有Node过多，因此在使用表格方法的过程中，可能会延迟检查是否存在树型桶。 * * Tree bins (i.e., bins whose elements are all TreeNodes) are * ordered primarily by hashCode, but in the case of ties, if two * elements are of the same &quot;class C implements Comparable&lt;C&gt;&quot;, * type then their compareTo method is used for ordering. (We * conservatively check generic types via reflection to validate * this -- see method comparableClassFor). The added complexity * of tree bins is worthwhile in providing worst-case O(log n) * operations when keys either have distinct hashes or are * orderable, Thus, performance degrades gracefully under * accidental or malicious usages in which hashCode() methods * return values that are poorly distributed, as well as those in * which many keys share a hashCode, so long as they are also * Comparable. (If neither of these apply, we may waste about a * factor of two in time and space compared to taking no * precautions. But the only known cases stem from poor user * programming practices that are already so slow that this makes * little difference.) * 树箱（即，元素均为TreeNode的箱-树形桶）主要由hashCode排序，但在有联系的情况下，如果两个元素属于相同的 &quot;class C implements Comparable&lt;C&gt;&quot; 类型， * 则可以通过他们的compareTo方法进行排序。（我们通过反射保守地检查泛型类型以验证这一点 -- 看 comparableClassFor 方法） * 当键具有不同的哈希值或可排序时，在最坏的情况 O(log n) 操作下增加树箱的复杂性是值得的，因此，在意外或恶意使用中 hashCode() 方法返回分布不均的值的情况下，性能会优雅降低， * 许多键共享一个hashCode值时也是一样，只要它们也是可比较的。（如果这两种方法都不适用，那么与不采取预防措施相比，我们可能会在时间和空间上浪费大约两倍的时间。 * 但是，唯一已知的情况是由于不良的用户编程实践已经如此之慢，以至于几乎没有什么区别。） * * Because TreeNodes are about twice the size of regular nodes, we * use them only when bins contain enough nodes to warrant use * (see TREEIFY_THRESHOLD). And when they become too small (due to * removal or resizing) they are converted back to plain bins. In * usages with well-distributed user hashCodes, tree bins are * rarely used. Ideally, under random hashCodes, the frequency of * nodes in bins follows a Poisson distribution * (http://en.wikipedia.org/wiki/Poisson_distribution) with a * parameter of about 0.5 on average for the default resizing * threshold of 0.75, although with a large variance because of * resizing granularity. Ignoring variance, the expected * occurrences of list size k are (exp(-0.5) * pow(0.5, k) / * factorial(k)). The first values are: * * 0: 0.60653066 * 1: 0.30326533 * 2: 0.07581633 * 3: 0.01263606 * 4: 0.00157952 * 5: 0.00015795 * 6: 0.00001316 * 7: 0.00000094 * 8: 0.00000006 * more: less than 1 in ten million * 由于TreeNode的大小约为常规Node的两倍，因此仅在存储桶包含足够多的Node时，我们才使用它们（TreeNode）（请参阅TREEIFY_THRESHOLD）。 * 当它们变得太小（由于移除或调整大小）时，它们会转换回普通箱（普通箱放普通Node节点元素，树箱放TreeNode节点元素）。 * 在用户hashCode具有良好分布的用法中，很少使用树箱。理想情况下，在随机hashCodes下，箱中节点的频率遵循Poisson分布（http://en.wikipedia.org/wiki/Poisson_distribution）， * 其默认调整大小阈值为0.75，平均参数约为0.5，尽管 由于调整粒度的差异很大。 忽略方差，列表大小k的预期出现次数是（exp（-0.5）* pow（0.5，k）/ factorial（k））。 * The first values are: * * 0: 0.60653066 * 1: 0.30326533 * 2: 0.07581633 * 3: 0.01263606 * 4: 0.00157952 * 5: 0.00015795 * 6: 0.00001316 * 7: 0.00000094 * 8: 0.00000006 * more：小于一千万分之一 * * The root of a tree bin is normally its first node. However, * sometimes (currently only upon Iterator.remove), the root might * be elsewhere, but can be recovered following parent links * (method TreeNode.root()). * 树的根通常是它的第一个节点。但是，有时（当前仅在Iterator.remove上），根目录可能在其他位置，但是可以在父链接之后恢复（方法TreeNode.root()）。 * * All applicable internal methods accept a hash code as an * argument (as normally supplied from a public method), allowing * them to call each other without recomputing user hashCodes. * Most internal methods also accept a &quot;tab&quot; argument, that is * normally the current table, but may be a new or old one when * resizing or converting. * 所有适用的内部方法均接收哈希码作为参数（通常由公共方法提供），从而允许它们在不重新计算用户hashCode的情况下彼此调用。 * 大多数内部方法还接受“tab”参数，该参数通常是当前表，但在调整大小或转换时可以是新的或旧的。 * * When bin lists are treeified, split, or untreeified, we keep * them in the same relative access/traversal order (i.e., field * Node.next) to better preserve locality, and to slightly * simplify handling of splits and traversals that invoke * iterator.remove. When using comparators on insertion, to keep a * total ordering (or as close as is required here) across * rebalancings, we compare classes and identityHashCodes as * tie-breakers. * 当桶被树化，拆分或去树化时，在访问/遍历的顺序（即字段Node.next）中我们将它们保持相同的关系，以更好地保留局部性，并略微简化对调用iterator.remove的拆分和遍历的处理。 * 在使用比较器插入时，为了保持重新平衡的总体顺序（或此处要求的接近度），我们将classes和identityHashCodes进行比较作为顺序判定 * * The use and transitions among plain vs tree modes is * complicated by the existence of subclass LinkedHashMap. See * below for hook methods defined to be invoked upon insertion, * removal and access that allow LinkedHashMap internals to * otherwise remain independent of these mechanics. (This also * requires that a map instance be passed to some utility methods * that may create new nodes.) * 子类LinkedHashMap的存在使普通模式与树模式之间的使用和转换变得复杂。 * 请参见下面的钩子方法，这些钩子方法定义为在插入，删除和访问时被调用，这些方法允许LinkedHashMap内部保持独立于这些机制。 * （这还要求将map实例传递给一些可能创建新节点的工具型方法。） * * The concurrent-programming-like SSA-based coding style helps * avoid aliasing errors amid all of the twisty pointer operations. * 并发编程例如基于SSA的编码风格有助于避免所有偏移指针操作中的混叠错误。 * */ 静态变量>folded DEFAULT_INITIAL_CAPACITY 默认初始容量123456/** * The default initial capacity - MUST be a power of two. * 默认初始容量 - 必须为2的幂。 * 1左移4位 = 2的4次幂 = 16 */static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16 >folded MAXIMUM_CAPACITY 最大容量12345678/** * The maximum capacity, used if a higher value is implicitly specified * by either of the constructors with arguments. * MUST be a power of two &lt;= 1&lt;&lt;30. * 最大容量，如果任一构造函数使用参数隐式的指定了更高的值，则使用该容量。 * 容量必须为2的幂且 &lt;= 1 &lt;&lt; 30。 */static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; >folded DEFAULT_LOAD_FACTOR 默认负载因子12345/** * The load factor used when none specified in constructor. * 在构造函数中未指定时使用的负载系数。默认0.75 */static final float DEFAULT_LOAD_FACTOR = 0.75f; >folded TREEIFY_THRESHOLD 树化阈值1234567891011/** * The bin count threshold for using a tree rather than list for a * bin. Bins are converted to trees when adding an element to a * bin with at least this many nodes. The value must be greater * than 2 and should be at least 8 to mesh with assumptions in * tree removal about conversion back to plain bins upon * shrinkage. * 选择使用树结构而不是列表结构的计数阈值。桶里元素添加到至少具有这么多时，桶的结构会转换为树结构。 * 该值必须大于2，并且至少是8才能与树删除中的假设（即收缩时转换回原始列表结构的桶）相啮合 */static final int TREEIFY_THRESHOLD = 8; >folded UNTREEIFY_THRESHOLD 去树化阈值1234567/** * The bin count threshold for untreeifying a (split) bin during a * resize operation. Should be less than TREEIFY_THRESHOLD, and at * most 6 to mesh with shrinkage detection under removal. * 在resize操作期间用于去树化（拆分）箱的计数阈值。应小于TREEIFY_THRESHOLD（树化阈值），并且最大为6以与删除时的收缩检测相啮合。 */static final int UNTREEIFY_THRESHOLD = 6; >folded MIN_TREEIFY_CAPACITY 树结构存在时最小table表容量123456789/** * The smallest table capacity for which bins may be treeified. * (Otherwise the table is resized if too many nodes in a bin.) * Should be at least 4 * TREEIFY_THRESHOLD to avoid conflicts * between resizing and treeification thresholds. * 树结构存在的最小表容量。（否则，如果桶中的节点过多，则将调整表的大小 - 增加table数组长度。） * 应至少为 4 * TREEIFY_THRESHOLD，以避免调整大小和树化阈值之间发生冲突。 */static final int MIN_TREEIFY_CAPACITY = 64; 静态内部类>folded Node 普通节点123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * Basic hash bin node, used for most entries. (See below for * TreeNode subclass, and in LinkedHashMap for its Entry subclass.) * 基本哈希箱节点，用于大多数条目。（有关TreeNode子类的信息，请参见下文；有关Entry子类的信息，请参见LinkedHashMap。） * 节点对象包含四个属性：key值的hash值、key值、映射的值value、下一个节点对象 */static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; { final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) { this.hash = hash; this.key = key; this.value = value; this.next = next; } public final K getKey() { return key; } public final V getValue() { return value; } public final String toString() { return key + &quot;=&quot; + value; } public final int hashCode() { return Objects.hashCode(key) ^ Objects.hashCode(value); } public final V setValue(V newValue) { V oldValue = value; value = newValue; return oldValue; } public final boolean equals(Object o) { if (o == this) return true; if (o instanceof Map.Entry) { Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; } return false; }} 静态工具方法>folded hash 计算hash值1234567891011121314151617181920212223242526272829303132333435363738394041424344/* ---------------- Static utilities -------------- *//** * Computes key.hashCode() and spreads (XORs) higher bits of hash * to lower. Because the table uses power-of-two masking, sets of * hashes that vary only in bits above the current mask will * always collide. (Among known examples are sets of Float keys * holding consecutive whole numbers in small tables.) So we * apply a transform that spreads the impact of higher bits * downward. There is a tradeoff between speed, utility, and * quality of bit-spreading. Because many common sets of hashes * are already reasonably distributed (so don't benefit from * spreading), and because we use trees to handle large sets of * collisions in bins, we just XOR some shifted bits in the * cheapest possible way to reduce systematic lossage, as well as * to incorporate impact of the highest bits that would otherwise * never be used in index calculations because of table bounds. * 计算key.hashCode()并将哈希的较高位特征（XOR）扩展到较低位中。 * 由于该表使用2的幂次掩码，因此仅在当前掩码上方的位中发生变化的哈希集将始终发生冲突。 * （众所周知的例子是在小表中包含连续整数的Float键集。）因此，我们应用了一种变换，将向下扩展较高位的影响。 * 在速度，实用性和位扩展质量之间需要权衡。由于许多常见的哈希集已经合理分布（因此无法从扩展中受益），并且由于我们使用树来处理容器中的大量冲突， * 因此我们仅以最便宜的方式对一些移位后的位进行XOR（异或运算），以减少系统损失，以及合并较高位的影响，否则由于表范围的限制，这些位将永远不会在索引计算中使用。 * * 意思就是将高位的二进制特征合并到低位特征中（这么做的原因是后面定位数组下标使用的方法是： * hash &amp; (tab.length-1)，这个二进制运算使得hash高位被屏蔽没有起作用，所以为了保留高位的特征和影响而进行了扩展操作， * 保留高位特征可以减小hash碰撞）。 * 示例1：高低位异或运算 * h=key.hashcode() 1111 1101 1101 1111 0101 1101 0010 1001 * ^ * h &gt;&gt;&gt; 16 0000 0000 0000 0000 1111 1101 1101 1111 * ———————————————————————————————————————————————————————— * h ^ (h &gt;&gt;&gt; 16) 1111 1101 1101 1111 1010 0000 1111 0110 * * 示例2：定位元素所处的数组位置（假设此时数组长度=16） * hash 1111 1101 1101 1111 1010 0000 1111 0110 * &amp; * 16-1 0000 0000 0000 0000 0000 0000 0000 1111 * ———————————————————————————————————————————————————————— * hash &amp; (16-1) 0000 0000 0000 0000 0000 0000 0000 0110 */static final int hash(Object key) { int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);} >folded comparableClassFor123456789101112131415161718192021222324/** * Returns x's Class if it is of the form &quot;class C implements * Comparable&lt;C&gt;&quot;, else null. * 返回 x 的 class 如果 x instanceof Comparable * 否则返回 null */static Class&lt;?&gt; comparableClassFor(Object x) { if (x instanceof Comparable) { Class&lt;?&gt; c; Type[] ts, as; Type t; ParameterizedType p; if ((c = x.getClass()) == String.class) // bypass checks return c; if ((ts = c.getGenericInterfaces()) != null) { for (int i = 0; i &lt; ts.length; ++i) { if (((t = ts[i]) instanceof ParameterizedType) &amp;&amp; ((p = (ParameterizedType)t).getRawType() == Comparable.class) &amp;&amp; (as = p.getActualTypeArguments()) != null &amp;&amp; as.length == 1 &amp;&amp; as[0] == c) // type arg is c return c; } } } return null;} >folded compareComparables123456789/** * Returns k.compareTo(x) if x matches kc (k's screened comparable * class), else 0. */@SuppressWarnings({&quot;rawtypes&quot;,&quot;unchecked&quot;}) // for cast to Comparablestatic int compareComparables(Class&lt;?&gt; kc, Object k, Object x) { return (x == null || x.getClass() != kc ? 0 : ((Comparable)k).compareTo(x));} >folded tableSizeFor 生成数组长度值12345678910111213/** * Returns a power of two size for the given target capacity. * 对于给定的目标容量，返回一个2的次幂的值 */static final int tableSizeFor(int cap) { int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;} 成员属性>folded table 数组123456789101112/* ---------------- Fields -------------- *//** * The table, initialized on first use, and resized as * necessary. When allocated, length is always a power of two. * (We also tolerate length zero in some operations to allow * bootstrapping mechanics that are currently not needed.) * 该table在首次使用时初始化，并根据需要调整大小。 * 分配时，长度始终是2的幂。（在某些操作中，我们还允许长度为零，以允许使用当前不需要的引导机制。） * transient修饰，该属性值不会被序列化 */transient Node&lt;K,V&gt;[] table; >folded entrySet123456/** * Holds cached entrySet(). Note that AbstractMap fields are used * for keySet() and values(). * 保存缓存的entrySet() 注意，AbstractMap字段用于keySet()和values()。 */transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet; >folded size12345/** * The number of key-value mappings contained in this map. * 此map中包含的键-值映射数。 */transient int size; >folded modCount HashMap结构修改次数12345678910/** * The number of times this HashMap has been structurally modified * Structural modifications are those that change the number of mappings in * the HashMap or otherwise modify its internal structure (e.g., * rehash). This field is used to make iterators on Collection-views of * the HashMap fail-fast. (See ConcurrentModificationException). * 对该HashMap进行结构修改的次数，结构修改是指更改HashMap中映射次数或以其他方式修改其内部结构（例如，重新哈希）的修改。 * 此字段用于使HashMap的Collection-view上的迭代器快速失败。 （请参见ConcurrentModificationException）。 */transient int modCount; >folded threshold12345678910/** * The next size value at which to resize (capacity * load factor). * resize时下一个大小的值（容量 * 负载因子） * @serial */// (The javadoc description is true upon serialization.// Additionally, if the table array has not been allocated, this// field holds the initial array capacity, or zero signifying// DEFAULT_INITIAL_CAPACITY.)int threshold; >folded loadFactor 负载因子123456/** * The load factor for the hash table. * 哈希表的负载因子 * @serial */final float loadFactor; 成员方法>folded HashMap 构造方法1（初始容量，负载因子）1234567891011121314151617181920212223/* ---------------- Public operations -------------- *//** * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the specified initial * capacity and load factor. * * @param initialCapacity the initial capacity * @param loadFactor the load factor * @throws IllegalArgumentException if the initial capacity is negative * or the load factor is nonpositive */public HashMap(int initialCapacity, float loadFactor) { if (initialCapacity &lt; 0) throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(&quot;Illegal load factor: &quot; + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity);} >folded HashMap 构造方法2（初始容量）12345678910/** * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the specified initial * capacity and the default load factor (0.75). * * @param initialCapacity the initial capacity. * @throws IllegalArgumentException if the initial capacity is negative. */public HashMap(int initialCapacity) { this(initialCapacity, DEFAULT_LOAD_FACTOR);} >folded HashMap 构造方法312345678/** * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the default initial capacity * (16) and the default load factor (0.75). * 默认的初始容量（16）和默认的负载因子（0.75） */public HashMap() { this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted} >folded HashMap 构造方法4（Map类型对象）12345678910111213/** * Constructs a new &lt;tt&gt;HashMap&lt;/tt&gt; with the same mappings as the * specified &lt;tt&gt;Map&lt;/tt&gt;. The &lt;tt&gt;HashMap&lt;/tt&gt; is created with * default load factor (0.75) and an initial capacity sufficient to * hold the mappings in the specified &lt;tt&gt;Map&lt;/tt&gt;. * * @param m the map whose mappings are to be placed in this map * @throws NullPointerException if the specified map is null */public HashMap(Map&lt;? extends K, ? extends V&gt; m) { this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false);} >folded putMapEntries 将传入的map的元素全部put进去123456789101112131415161718192021222324252627/** * Implements Map.putAll and Map constructor * 实现了 Map.putAll 和 Map的构造器 * * @param m the map * @param evict false when initially constructing this map, else * true (relayed to method afterNodeInsertion). */final void putMapEntries(Map&lt;? extends K, ? extends V&gt; m, boolean evict) { int s = m.size(); if (s &gt; 0) { if (table == null) { // pre-size float ft = ((float)s / loadFactor) + 1.0F; int t = ((ft &lt; (float)MAXIMUM_CAPACITY) ? (int)ft : MAXIMUM_CAPACITY); if (t &gt; threshold) threshold = tableSizeFor(t); } else if (s &gt; threshold) resize(); for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) { K key = e.getKey(); V value = e.getValue(); putVal(hash(key), key, value, false, evict); } }} >folded size 返回键-值映射数量12345678/** * Returns the number of key-value mappings in this map. * * @return the number of key-value mappings in this map */public int size() { return size;} >folded isEmpty 返回映射数是否为012345678/** * Returns &lt;tt&gt;true&lt;/tt&gt; if this map contains no key-value mappings. * * @return &lt;tt&gt;true&lt;/tt&gt; if this map contains no key-value mappings */public boolean isEmpty() { return size == 0;} >folded get 根据key获取value123456789101112131415161718192021/** * Returns the value to which the specified key is mapped, * or {@code null} if this map contains no mapping for the key. * * &lt;p&gt;More formally, if this map contains a mapping from a key * {@code k} to a value {@code v} such that {@code (key==null ? k==null : * key.equals(k))}, then this method returns {@code v}; otherwise * it returns {@code null}. (There can be at most one such mapping.) * * &lt;p&gt;A return value of {@code null} does not &lt;i&gt;necessarily&lt;/i&gt; * indicate that the map contains no mapping for the key; it's also * possible that the map explicitly maps the key to {@code null}. * The {@link #containsKey containsKey} operation may be used to * distinguish these two cases. * * @see #put(Object, Object) */public V get(Object key) { Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;} >folded getNode 根据hash值和key获取Node节点（Node/TreeNode）1234567891011121314151617181920212223242526/** * Implements Map.get and related methods * * @param hash hash for key * @param key the key * @return the node, or null if none */final Node&lt;K,V&gt; getNode(int hash, Object key) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) { if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) { if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do { if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; } while ((e = e.next) != null); } } return null;} >folded containsKey 返回map是否包含此键1234567891011/** * Returns &lt;tt&gt;true&lt;/tt&gt; if this map contains a mapping for the * specified key. * * @param key The key whose presence in this map is to be tested * @return &lt;tt&gt;true&lt;/tt&gt; if this map contains a mapping for the specified * key. */public boolean containsKey(Object key) { return getNode(hash(key), key) != null;} >folded put 放元素（key，value）12345678910111213141516/** * Associates the specified value with the specified key in this map. * If the map previously contained a mapping for the key, the old * value is replaced. * 将指定值与该映射中的指定键相关联。如果该映射先前包含该键的映射，则替换旧值 * * @param key key with which the specified value is to be associated * @param value value to be associated with the specified key * @return the previous value associated with &lt;tt&gt;key&lt;/tt&gt;, or * &lt;tt&gt;null&lt;/tt&gt; if there was no mapping for &lt;tt&gt;key&lt;/tt&gt;. * (A &lt;tt&gt;null&lt;/tt&gt; return can also indicate that the map * previously associated &lt;tt&gt;null&lt;/tt&gt; with &lt;tt&gt;key&lt;/tt&gt;.) */public V put(K key, V value) { return putVal(hash(key), key, value, false, true);} >folded putVal 具体put方法的实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * Implements Map.put and related methods * * @param hash hash for key * @param key the key * @param value the value to put * @param onlyIfAbsent if true, don't change existing value * @param evict if false, the table is in creation mode. * @return previous value, or null if none */final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else { Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else { for (int binCount = 0; ; ++binCount) { if ((e = p.next) == null) { p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; } if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; } } if (e != null) { // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; } } ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;} >folded resize 重建table表。初始化或2倍扩容12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182/** * Initializes or doubles table size. If null, allocates in * accord with initial capacity target held in field threshold. * Otherwise, because we are using power-of-two expansion, the * elements from each bin must either stay at same index, or move * with a power of two offset in the new table. * * @return the table */final Node&lt;K,V&gt;[] resize() { Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) { if (oldCap &gt;= MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return oldTab; } else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold } else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else { // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); } if (newThr == 0) { float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); } threshold = newThr; @SuppressWarnings({&quot;rawtypes&quot;,&quot;unchecked&quot;}) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) { for (int j = 0; j &lt; oldCap; ++j) { Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) { oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else { // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do { next = e.next; if ((e.hash &amp; oldCap) == 0) { if (loTail == null) loHead = e; else loTail.next = e; loTail = e; } else { if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; } } while ((e = next) != null); if (loTail != null) { loTail.next = null; newTab[j] = loHead; } if (hiTail != null) { hiTail.next = null; newTab[j + oldCap] = hiHead; } } } } } return newTab;} >folded treeifyBin 树化给定hash值对应的桶所有元素1234567891011121314151617181920212223242526/** * Replaces all linked nodes in bin at index for given hash unless * table is too small, in which case resizes instead. * 树化给定hash值对应的桶所有元素，除非table表太小 - tab.length &lt; MIN_TREEIFY_CAPACITY。 * table表太小的情况就进行一遍resize表重建。 */final void treeifyBin(Node&lt;K,V&gt;[] tab, int hash) { int n, index; Node&lt;K,V&gt; e; if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) resize(); else if ((e = tab[index = (n - 1) &amp; hash]) != null) { TreeNode&lt;K,V&gt; hd = null, tl = null; do { TreeNode&lt;K,V&gt; p = replacementTreeNode(e, null); if (tl == null) hd = p; else { p.prev = tl; tl.next = p; } tl = p; } while ((e = e.next) != null); if ((tab[index] = hd) != null) hd.treeify(tab); }} >folded putAll 将传入的map的元素全部put进去1234567891011/** * Copies all of the mappings from the specified map to this map. * These mappings will replace any mappings that this map had for * any of the keys currently in the specified map. * * @param m mappings to be stored in this map * @throws NullPointerException if the specified map is null */public void putAll(Map&lt;? extends K, ? extends V&gt; m) { putMapEntries(m, true);} >folded remove 删除指定键的映射1234567891011121314/** * Removes the mapping for the specified key from this map if present. * 如果存在，则从此map中删除指定键的映射。 * @param key key whose mapping is to be removed from the map * @return the previous value associated with &lt;tt&gt;key&lt;/tt&gt;, or * &lt;tt&gt;null&lt;/tt&gt; if there was no mapping for &lt;tt&gt;key&lt;/tt&gt;. * (A &lt;tt&gt;null&lt;/tt&gt; return can also indicate that the map * previously associated &lt;tt&gt;null&lt;/tt&gt; with &lt;tt&gt;key&lt;/tt&gt;.) */public V remove(Object key) { Node&lt;K,V&gt; e; return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value;} >folded removeNode 删除指定键的节点1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * Implements Map.remove and related methods * * @param hash hash for key * @param key the key * @param value the value to match if matchValue, else ignored * @param matchValue if true only remove if value is equal * @param movable if false do not move other nodes while removing * @return the node, or null if none */final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) { Node&lt;K,V&gt; node = null, e; K k; V v; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; else if ((e = p.next) != null) { if (p instanceof TreeNode) node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); else { do { if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) { node = e; break; } p = e; } while ((e = e.next) != null); } } if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) { if (node instanceof TreeNode) ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); else if (node == p) tab[index] = node.next; else p.next = node.next; ++modCount; --size; afterNodeRemoval(node); return node; } } return null;} >folded clear 删除全部键值映射12345678910111213/** * Removes all of the mappings from this map. * The map will be empty after this call returns. */public void clear() { Node&lt;K,V&gt;[] tab; modCount++; if ((tab = table) != null &amp;&amp; size &gt; 0) { size = 0; for (int i = 0; i &lt; tab.length; ++i) tab[i] = null; }} >folded containsValue 判断是否包含此值123456789101112131415161718192021/** * Returns &lt;tt&gt;true&lt;/tt&gt; if this map maps one or more keys to the * specified value. * * @param value value whose presence in this map is to be tested * @return &lt;tt&gt;true&lt;/tt&gt; if this map maps one or more keys to the * specified value */public boolean containsValue(Object value) { Node&lt;K,V&gt;[] tab; V v; if ((tab = table) != null &amp;&amp; size &gt; 0) { for (int i = 0; i &lt; tab.length; ++i) { for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) { if ((v = e.value) == value || (value != null &amp;&amp; value.equals(v))) return true; } } } return false;} >folded keySet 返回map包含的所有key值set集合12345678910111213141516171819/** * Returns a {@link Set} view of the keys contained in this map. * The set is backed by the map, so changes to the map are * reflected in the set, and vice-versa. If the map is modified * while an iteration over the set is in progress (except through * the iterator's own &lt;tt&gt;remove&lt;/tt&gt; operation), the results of * the iteration are undefined. The set supports element removal, * which removes the corresponding mapping from the map, via the * &lt;tt&gt;Iterator.remove&lt;/tt&gt;, &lt;tt&gt;Set.remove&lt;/tt&gt;, * &lt;tt&gt;removeAll&lt;/tt&gt;, &lt;tt&gt;retainAll&lt;/tt&gt;, and &lt;tt&gt;clear&lt;/tt&gt; * operations. It does not support the &lt;tt&gt;add&lt;/tt&gt; or &lt;tt&gt;addAll&lt;/tt&gt; * operations. * * @return a set view of the keys contained in this map */public Set&lt;K&gt; keySet() { Set&lt;K&gt; ks; return (ks = keySet) == null ? (keySet = new KeySet()) : ks;} KeySet内部类>folded1234567891011121314151617181920212223242526final class KeySet extends AbstractSet&lt;K&gt; { public final int size() { return size; } public final void clear() { HashMap.this.clear(); } public final Iterator&lt;K&gt; iterator() { return new KeyIterator(); } public final boolean contains(Object o) { return containsKey(o); } public final boolean remove(Object key) { return removeNode(hash(key), key, null, false, true) != null; } public final Spliterator&lt;K&gt; spliterator() { return new KeySpliterator&lt;&gt;(HashMap.this, 0, -1, 0, 0); } public final void forEach(Consumer&lt;? super K&gt; action) { Node&lt;K,V&gt;[] tab; if (action == null) throw new NullPointerException(); if (size &gt; 0 &amp;&amp; (tab = table) != null) { int mc = modCount; for (int i = 0; i &lt; tab.length; ++i) { for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) action.accept(e.key); } if (modCount != mc) throw new ConcurrentModificationException(); } }} >folded values 返回map中所有value的集合12345678910111213141516171819/** * Returns a {@link Collection} view of the values contained in this map. * The collection is backed by the map, so changes to the map are * reflected in the collection, and vice-versa. If the map is * modified while an iteration over the collection is in progress * (except through the iterator's own &lt;tt&gt;remove&lt;/tt&gt; operation), * the results of the iteration are undefined. The collection * supports element removal, which removes the corresponding * mapping from the map, via the &lt;tt&gt;Iterator.remove&lt;/tt&gt;, * &lt;tt&gt;Collection.remove&lt;/tt&gt;, &lt;tt&gt;removeAll&lt;/tt&gt;, * &lt;tt&gt;retainAll&lt;/tt&gt; and &lt;tt&gt;clear&lt;/tt&gt; operations. It does not * support the &lt;tt&gt;add&lt;/tt&gt; or &lt;tt&gt;addAll&lt;/tt&gt; operations. * * @return a view of the values contained in this map */public Collection&lt;V&gt; values() { Collection&lt;V&gt; vs; return (vs = values) == null ? (values = new Values()) : vs;} Values内部类>folded1234567891011121314151617181920212223final class Values extends AbstractCollection&lt;V&gt; { public final int size() { return size; } public final void clear() { HashMap.this.clear(); } public final Iterator&lt;V&gt; iterator() { return new ValueIterator(); } public final boolean contains(Object o) { return containsValue(o); } public final Spliterator&lt;V&gt; spliterator() { return new ValueSpliterator&lt;&gt;(HashMap.this, 0, -1, 0, 0); } public final void forEach(Consumer&lt;? super V&gt; action) { Node&lt;K,V&gt;[] tab; if (action == null) throw new NullPointerException(); if (size &gt; 0 &amp;&amp; (tab = table) != null) { int mc = modCount; for (int i = 0; i &lt; tab.length; ++i) { for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) action.accept(e.value); } if (modCount != mc) throw new ConcurrentModificationException(); } }} >folded entrySet 返回map包含的键值映射集合1234567891011121314151617181920/** * Returns a {@link Set} view of the mappings contained in this map. * The set is backed by the map, so changes to the map are * reflected in the set, and vice-versa. If the map is modified * while an iteration over the set is in progress (except through * the iterator's own &lt;tt&gt;remove&lt;/tt&gt; operation, or through the * &lt;tt&gt;setValue&lt;/tt&gt; operation on a map entry returned by the * iterator) the results of the iteration are undefined. The set * supports element removal, which removes the corresponding * mapping from the map, via the &lt;tt&gt;Iterator.remove&lt;/tt&gt;, * &lt;tt&gt;Set.remove&lt;/tt&gt;, &lt;tt&gt;removeAll&lt;/tt&gt;, &lt;tt&gt;retainAll&lt;/tt&gt; and * &lt;tt&gt;clear&lt;/tt&gt; operations. It does not support the * &lt;tt&gt;add&lt;/tt&gt; or &lt;tt&gt;addAll&lt;/tt&gt; operations. * * @return a set view of the mappings contained in this map */public Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet() { Set&lt;Map.Entry&lt;K,V&gt;&gt; es; return (es = entrySet) == null ? (entrySet = new EntrySet()) : es;} EntrySet内部类>folded1234567891011121314151617181920212223242526272829303132333435363738394041final class EntrySet extends AbstractSet&lt;Map.Entry&lt;K,V&gt;&gt; { public final int size() { return size; } public final void clear() { HashMap.this.clear(); } public final Iterator&lt;Map.Entry&lt;K,V&gt;&gt; iterator() { return new EntryIterator(); } public final boolean contains(Object o) { if (!(o instanceof Map.Entry)) return false; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;) o; Object key = e.getKey(); Node&lt;K,V&gt; candidate = getNode(hash(key), key); return candidate != null &amp;&amp; candidate.equals(e); } public final boolean remove(Object o) { if (o instanceof Map.Entry) { Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;) o; Object key = e.getKey(); Object value = e.getValue(); return removeNode(hash(key), key, value, true, true) != null; } return false; } public final Spliterator&lt;Map.Entry&lt;K,V&gt;&gt; spliterator() { return new EntrySpliterator&lt;&gt;(HashMap.this, 0, -1, 0, 0); } public final void forEach(Consumer&lt;? super Map.Entry&lt;K,V&gt;&gt; action) { Node&lt;K,V&gt;[] tab; if (action == null) throw new NullPointerException(); if (size &gt; 0 &amp;&amp; (tab = table) != null) { int mc = modCount; for (int i = 0; i &lt; tab.length; ++i) { for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) action.accept(e); } if (modCount != mc) throw new ConcurrentModificationException(); } }} 重写JDK8 Map扩展方法>folded123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260// Overrides of JDK8 Map extension methods@Overridepublic V getOrDefault(Object key, V defaultValue) { Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? defaultValue : e.value;}@Overridepublic V putIfAbsent(K key, V value) { return putVal(hash(key), key, value, true, true);}@Overridepublic boolean remove(Object key, Object value) { return removeNode(hash(key), key, value, true, true) != null;}@Overridepublic boolean replace(K key, V oldValue, V newValue) { Node&lt;K,V&gt; e; V v; if ((e = getNode(hash(key), key)) != null &amp;&amp; ((v = e.value) == oldValue || (v != null &amp;&amp; v.equals(oldValue)))) { e.value = newValue; afterNodeAccess(e); return true; } return false;}@Overridepublic V replace(K key, V value) { Node&lt;K,V&gt; e; if ((e = getNode(hash(key), key)) != null) { V oldValue = e.value; e.value = value; afterNodeAccess(e); return oldValue; } return null;}@Overridepublic V computeIfAbsent(K key, Function&lt;? super K, ? extends V&gt; mappingFunction) { if (mappingFunction == null) throw new NullPointerException(); int hash = hash(key); Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first; int n, i; int binCount = 0; TreeNode&lt;K,V&gt; t = null; Node&lt;K,V&gt; old = null; if (size &gt; threshold || (tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((first = tab[i = (n - 1) &amp; hash]) != null) { if (first instanceof TreeNode) old = (t = (TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); else { Node&lt;K,V&gt; e = first; K k; do { if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) { old = e; break; } ++binCount; } while ((e = e.next) != null); } V oldValue; if (old != null &amp;&amp; (oldValue = old.value) != null) { afterNodeAccess(old); return oldValue; } } V v = mappingFunction.apply(key); if (v == null) { return null; } else if (old != null) { old.value = v; afterNodeAccess(old); return v; } else if (t != null) t.putTreeVal(this, tab, hash, key, v); else { tab[i] = newNode(hash, key, v, first); if (binCount &gt;= TREEIFY_THRESHOLD - 1) treeifyBin(tab, hash); } ++modCount; ++size; afterNodeInsertion(true); return v;}public V computeIfPresent(K key, BiFunction&lt;? super K, ? super V, ? extends V&gt; remappingFunction) { if (remappingFunction == null) throw new NullPointerException(); Node&lt;K,V&gt; e; V oldValue; int hash = hash(key); if ((e = getNode(hash, key)) != null &amp;&amp; (oldValue = e.value) != null) { V v = remappingFunction.apply(key, oldValue); if (v != null) { e.value = v; afterNodeAccess(e); return v; } else removeNode(hash, key, null, false, true); } return null;}@Overridepublic V compute(K key, BiFunction&lt;? super K, ? super V, ? extends V&gt; remappingFunction) { if (remappingFunction == null) throw new NullPointerException(); int hash = hash(key); Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first; int n, i; int binCount = 0; TreeNode&lt;K,V&gt; t = null; Node&lt;K,V&gt; old = null; if (size &gt; threshold || (tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((first = tab[i = (n - 1) &amp; hash]) != null) { if (first instanceof TreeNode) old = (t = (TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); else { Node&lt;K,V&gt; e = first; K k; do { if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) { old = e; break; } ++binCount; } while ((e = e.next) != null); } } V oldValue = (old == null) ? null : old.value; V v = remappingFunction.apply(key, oldValue); if (old != null) { if (v != null) { old.value = v; afterNodeAccess(old); } else removeNode(hash, key, null, false, true); } else if (v != null) { if (t != null) t.putTreeVal(this, tab, hash, key, v); else { tab[i] = newNode(hash, key, v, first); if (binCount &gt;= TREEIFY_THRESHOLD - 1) treeifyBin(tab, hash); } ++modCount; ++size; afterNodeInsertion(true); } return v;}@Overridepublic V merge(K key, V value, BiFunction&lt;? super V, ? super V, ? extends V&gt; remappingFunction) { if (value == null) throw new NullPointerException(); if (remappingFunction == null) throw new NullPointerException(); int hash = hash(key); Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first; int n, i; int binCount = 0; TreeNode&lt;K,V&gt; t = null; Node&lt;K,V&gt; old = null; if (size &gt; threshold || (tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((first = tab[i = (n - 1) &amp; hash]) != null) { if (first instanceof TreeNode) old = (t = (TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); else { Node&lt;K,V&gt; e = first; K k; do { if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) { old = e; break; } ++binCount; } while ((e = e.next) != null); } } if (old != null) { V v; if (old.value != null) v = remappingFunction.apply(old.value, value); else v = value; if (v != null) { old.value = v; afterNodeAccess(old); } else removeNode(hash, key, null, false, true); return v; } if (value != null) { if (t != null) t.putTreeVal(this, tab, hash, key, value); else { tab[i] = newNode(hash, key, value, first); if (binCount &gt;= TREEIFY_THRESHOLD - 1) treeifyBin(tab, hash); } ++modCount; ++size; afterNodeInsertion(true); } return value;}@Overridepublic void forEach(BiConsumer&lt;? super K, ? super V&gt; action) { Node&lt;K,V&gt;[] tab; if (action == null) throw new NullPointerException(); if (size &gt; 0 &amp;&amp; (tab = table) != null) { int mc = modCount; for (int i = 0; i &lt; tab.length; ++i) { for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) action.accept(e.key, e.value); } if (modCount != mc) throw new ConcurrentModificationException(); }}@Overridepublic void replaceAll(BiFunction&lt;? super K, ? super V, ? extends V&gt; function) { Node&lt;K,V&gt;[] tab; if (function == null) throw new NullPointerException(); if (size &gt; 0 &amp;&amp; (tab = table) != null) { int mc = modCount; for (int i = 0; i &lt; tab.length; ++i) { for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) { e.value = function.apply(e.key, e.value); } } if (modCount != mc) throw new ConcurrentModificationException(); }} clone 和 序列化方法>folded clone123456789101112131415161718192021222324/* ------------------------------------------------------------ */// Cloning and serialization/** * Returns a shallow copy of this &lt;tt&gt;HashMap&lt;/tt&gt; instance: the keys and * values themselves are not cloned. * 返回此HashMap实例的浅副本：键和值本身不会被克隆。 * * @return a shallow copy of this map */@SuppressWarnings(&quot;unchecked&quot;)@Overridepublic Object clone() { HashMap&lt;K,V&gt; result; try { result = (HashMap&lt;K,V&gt;)super.clone(); } catch (CloneNotSupportedException e) { // this shouldn't happen, since we are Cloneable throw new InternalError(e); } result.reinitialize(); result.putMapEntries(this, false); return result;} >folded serialization 用于序列化的一些方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576// These methods are also used when serializing HashSetsfinal float loadFactor() { return loadFactor; }final int capacity() { return (table != null) ? table.length : (threshold &gt; 0) ? threshold : DEFAULT_INITIAL_CAPACITY;}/** * Save the state of the &lt;tt&gt;HashMap&lt;/tt&gt; instance to a stream (i.e., * serialize it). * 将HashMap实例的状态保存到流中（即序列化它）。 * * @serialData The &lt;i&gt;capacity&lt;/i&gt; of the HashMap (the length of the * bucket array) is emitted (int), followed by the * &lt;i&gt;size&lt;/i&gt; (an int, the number of key-value * mappings), followed by the key (Object) and value (Object) * for each key-value mapping. The key-value mappings are * emitted in no particular order. */private void writeObject(java.io.ObjectOutputStream s) throws IOException { int buckets = capacity(); // Write out the threshold, loadfactor, and any hidden stuff s.defaultWriteObject(); s.writeInt(buckets); s.writeInt(size); internalWriteEntries(s);}/** * Reconstitute the {@code HashMap} instance from a stream (i.e., * deserialize it). * 从流中重建HashMap实例（即反序列化它）。 */private void readObject(java.io.ObjectInputStream s) throws IOException, ClassNotFoundException { // Read in the threshold (ignored), loadfactor, and any hidden stuff s.defaultReadObject(); reinitialize(); if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new InvalidObjectException(&quot;Illegal load factor: &quot; + loadFactor); s.readInt(); // Read and ignore number of buckets int mappings = s.readInt(); // Read number of mappings (size) if (mappings &lt; 0) throw new InvalidObjectException(&quot;Illegal mappings count: &quot; + mappings); else if (mappings &gt; 0) { // (if zero, use defaults) // Size the table using given load factor only if within // range of 0.25...4.0 float lf = Math.min(Math.max(0.25f, loadFactor), 4.0f); float fc = (float)mappings / lf + 1.0f; int cap = ((fc &lt; DEFAULT_INITIAL_CAPACITY) ? DEFAULT_INITIAL_CAPACITY : (fc &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : tableSizeFor((int)fc)); float ft = (float)cap * lf; threshold = ((cap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; MAXIMUM_CAPACITY) ? (int)ft : Integer.MAX_VALUE); @SuppressWarnings({&quot;rawtypes&quot;,&quot;unchecked&quot;}) Node&lt;K,V&gt;[] tab = (Node&lt;K,V&gt;[])new Node[cap]; table = tab; // Read the keys and values, and put the mappings in the HashMap for (int i = 0; i &lt; mappings; i++) { @SuppressWarnings(&quot;unchecked&quot;) K key = (K) s.readObject(); @SuppressWarnings(&quot;unchecked&quot;) V value = (V) s.readObject(); putVal(hash(key), key, value, false, false); } }} iterators 迭代方法>folded HashIterator hash迭代器抽象内部类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/* ------------------------------------------------------------ */// iteratorsabstract class HashIterator { Node&lt;K,V&gt; next; // next entry to return Node&lt;K,V&gt; current; // current entry int expectedModCount; // for fast-fail int index; // current slot HashIterator() { expectedModCount = modCount; Node&lt;K,V&gt;[] t = table; current = next = null; index = 0; if (t != null &amp;&amp; size &gt; 0) { // advance to first entry do {} while (index &lt; t.length &amp;&amp; (next = t[index++]) == null); } } public final boolean hasNext() { return next != null; } final Node&lt;K,V&gt; nextNode() { Node&lt;K,V&gt;[] t; Node&lt;K,V&gt; e = next; if (modCount != expectedModCount) throw new ConcurrentModificationException(); if (e == null) throw new NoSuchElementException(); if ((next = (current = e).next) == null &amp;&amp; (t = table) != null) { do {} while (index &lt; t.length &amp;&amp; (next = t[index++]) == null); } return e; } public final void remove() { Node&lt;K,V&gt; p = current; if (p == null) throw new IllegalStateException(); if (modCount != expectedModCount) throw new ConcurrentModificationException(); current = null; K key = p.key; removeNode(hash(key), key, null, false, false); expectedModCount = modCount; }} >folded HashIterator的三个子类：key、value、映射迭代器1234567891011121314final class KeyIterator extends HashIterator implements Iterator&lt;K&gt; { public final K next() { return nextNode().key; }}final class ValueIterator extends HashIterator implements Iterator&lt;V&gt; { public final V next() { return nextNode().value; }}final class EntryIterator extends HashIterator implements Iterator&lt;Map.Entry&lt;K,V&gt;&gt; { public final Map.Entry&lt;K,V&gt; next() { return nextNode(); }} spliterators 分离器>folded HashMapSpliterator分离器静态内部类1234567891011121314151617181920212223242526272829303132333435363738/* ------------------------------------------------------------ */// spliteratorsstatic class HashMapSpliterator&lt;K,V&gt; { final HashMap&lt;K,V&gt; map; Node&lt;K,V&gt; current; // current node | 当前节点 int index; // current index, modified on advance/split | 当前索引，在 advance/split 时修改 int fence; // one past last index | 最后一个索引 int est; // size estimate | 预估大小 int expectedModCount; // for comodification checks | 预期修改数，用于修改检查 HashMapSpliterator(HashMap&lt;K,V&gt; m, int origin, int fence, int est, int expectedModCount) { this.map = m; this.index = origin; this.fence = fence; this.est = est; this.expectedModCount = expectedModCount; } final int getFence() { // initialize fence and size on first use | 第一次使用时初始化fence和est、expectedModCount int hi; if ((hi = fence) &lt; 0) { HashMap&lt;K,V&gt; m = map; est = m.size; expectedModCount = m.modCount; Node&lt;K,V&gt;[] tab = m.table; hi = fence = (tab == null) ? 0 : tab.length; } return hi; } public final long estimateSize() { getFence(); // force init return (long) est; }} >folded KeySpliterator分离器1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071static final class KeySpliterator&lt;K,V&gt; extends HashMapSpliterator&lt;K,V&gt; implements Spliterator&lt;K&gt; { KeySpliterator(HashMap&lt;K,V&gt; m, int origin, int fence, int est, int expectedModCount) { super(m, origin, fence, est, expectedModCount); } public KeySpliterator&lt;K,V&gt; trySplit() { int hi = getFence(), lo = index, mid = (lo + hi) &gt;&gt;&gt; 1; return (lo &gt;= mid || current != null) ? null : new KeySpliterator&lt;&gt;(map, lo, index = mid, est &gt;&gt;&gt;= 1, expectedModCount); } public void forEachRemaining(Consumer&lt;? super K&gt; action) { int i, hi, mc; if (action == null) throw new NullPointerException(); HashMap&lt;K,V&gt; m = map; Node&lt;K,V&gt;[] tab = m.table; if ((hi = fence) &lt; 0) { mc = expectedModCount = m.modCount; hi = fence = (tab == null) ? 0 : tab.length; } else mc = expectedModCount; if (tab != null &amp;&amp; tab.length &gt;= hi &amp;&amp; (i = index) &gt;= 0 &amp;&amp; (i &lt; (index = hi) || current != null)) { Node&lt;K,V&gt; p = current; current = null; do { if (p == null) p = tab[i++]; else { action.accept(p.key); p = p.next; } } while (p != null || i &lt; hi); if (m.modCount != mc) throw new ConcurrentModificationException(); } } public boolean tryAdvance(Consumer&lt;? super K&gt; action) { int hi; if (action == null) throw new NullPointerException(); Node&lt;K,V&gt;[] tab = map.table; if (tab != null &amp;&amp; tab.length &gt;= (hi = getFence()) &amp;&amp; index &gt;= 0) { while (current != null || index &lt; hi) { if (current == null) current = tab[index++]; else { K k = current.key; current = current.next; action.accept(k); if (map.modCount != expectedModCount) throw new ConcurrentModificationException(); return true; } } } return false; } public int characteristics() { return (fence &lt; 0 || est == map.size ? Spliterator.SIZED : 0) | Spliterator.DISTINCT; }} >folded ValueSpliterator分离器12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970static final class ValueSpliterator&lt;K,V&gt; extends HashMapSpliterator&lt;K,V&gt; implements Spliterator&lt;V&gt; { ValueSpliterator(HashMap&lt;K,V&gt; m, int origin, int fence, int est, int expectedModCount) { super(m, origin, fence, est, expectedModCount); } public ValueSpliterator&lt;K,V&gt; trySplit() { int hi = getFence(), lo = index, mid = (lo + hi) &gt;&gt;&gt; 1; return (lo &gt;= mid || current != null) ? null : new ValueSpliterator&lt;&gt;(map, lo, index = mid, est &gt;&gt;&gt;= 1, expectedModCount); } public void forEachRemaining(Consumer&lt;? super V&gt; action) { int i, hi, mc; if (action == null) throw new NullPointerException(); HashMap&lt;K,V&gt; m = map; Node&lt;K,V&gt;[] tab = m.table; if ((hi = fence) &lt; 0) { mc = expectedModCount = m.modCount; hi = fence = (tab == null) ? 0 : tab.length; } else mc = expectedModCount; if (tab != null &amp;&amp; tab.length &gt;= hi &amp;&amp; (i = index) &gt;= 0 &amp;&amp; (i &lt; (index = hi) || current != null)) { Node&lt;K,V&gt; p = current; current = null; do { if (p == null) p = tab[i++]; else { action.accept(p.value); p = p.next; } } while (p != null || i &lt; hi); if (m.modCount != mc) throw new ConcurrentModificationException(); } } public boolean tryAdvance(Consumer&lt;? super V&gt; action) { int hi; if (action == null) throw new NullPointerException(); Node&lt;K,V&gt;[] tab = map.table; if (tab != null &amp;&amp; tab.length &gt;= (hi = getFence()) &amp;&amp; index &gt;= 0) { while (current != null || index &lt; hi) { if (current == null) current = tab[index++]; else { V v = current.value; current = current.next; action.accept(v); if (map.modCount != expectedModCount) throw new ConcurrentModificationException(); return true; } } } return false; } public int characteristics() { return (fence &lt; 0 || est == map.size ? Spliterator.SIZED : 0); }} >folded EntrySpliterator分离器1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071static final class EntrySpliterator&lt;K,V&gt; extends HashMapSpliterator&lt;K,V&gt; implements Spliterator&lt;Map.Entry&lt;K,V&gt;&gt; { EntrySpliterator(HashMap&lt;K,V&gt; m, int origin, int fence, int est, int expectedModCount) { super(m, origin, fence, est, expectedModCount); } public EntrySpliterator&lt;K,V&gt; trySplit() { int hi = getFence(), lo = index, mid = (lo + hi) &gt;&gt;&gt; 1; return (lo &gt;= mid || current != null) ? null : new EntrySpliterator&lt;&gt;(map, lo, index = mid, est &gt;&gt;&gt;= 1, expectedModCount); } public void forEachRemaining(Consumer&lt;? super Map.Entry&lt;K,V&gt;&gt; action) { int i, hi, mc; if (action == null) throw new NullPointerException(); HashMap&lt;K,V&gt; m = map; Node&lt;K,V&gt;[] tab = m.table; if ((hi = fence) &lt; 0) { mc = expectedModCount = m.modCount; hi = fence = (tab == null) ? 0 : tab.length; } else mc = expectedModCount; if (tab != null &amp;&amp; tab.length &gt;= hi &amp;&amp; (i = index) &gt;= 0 &amp;&amp; (i &lt; (index = hi) || current != null)) { Node&lt;K,V&gt; p = current; current = null; do { if (p == null) p = tab[i++]; else { action.accept(p); p = p.next; } } while (p != null || i &lt; hi); if (m.modCount != mc) throw new ConcurrentModificationException(); } } public boolean tryAdvance(Consumer&lt;? super Map.Entry&lt;K,V&gt;&gt; action) { int hi; if (action == null) throw new NullPointerException(); Node&lt;K,V&gt;[] tab = map.table; if (tab != null &amp;&amp; tab.length &gt;= (hi = getFence()) &amp;&amp; index &gt;= 0) { while (current != null || index &lt; hi) { if (current == null) current = tab[index++]; else { Node&lt;K,V&gt; e = current; current = current.next; action.accept(e); if (map.modCount != expectedModCount) throw new ConcurrentModificationException(); return true; } } } return false; } public int characteristics() { return (fence &lt; 0 || est == map.size ? Spliterator.SIZED : 0) | Spliterator.DISTINCT; }} LinkedHashMap support LinkedHashMap支持>folded1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/* ------------------------------------------------------------ */// LinkedHashMap support/* * The following package-protected methods are designed to be * overridden by LinkedHashMap, but not by any other subclass. * Nearly all other internal methods are also package-protected * but are declared final, so can be used by LinkedHashMap, view * classes, and HashSet. * 下面的受程序包保护的方法旨在被LinkedHashMap覆盖，但不能被任何其他子类覆盖。 * 几乎所有其他内部方法也受程序包保护，但都声明为final，因此LinkedHashMap，视图类和HashSet可以使用它。 */// Create a regular (non-tree) node | 创建一个常规（非树）节点Node&lt;K,V&gt; newNode(int hash, K key, V value, Node&lt;K,V&gt; next) { return new Node&lt;&gt;(hash, key, value, next);}// For conversion from TreeNodes to plain nodes | 用于从TreeNodes转换为常规节点Node&lt;K,V&gt; replacementNode(Node&lt;K,V&gt; p, Node&lt;K,V&gt; next) { return new Node&lt;&gt;(p.hash, p.key, p.value, next);}// Create a tree bin node | 创建一个树节点TreeNode&lt;K,V&gt; newTreeNode(int hash, K key, V value, Node&lt;K,V&gt; next) { return new TreeNode&lt;&gt;(hash, key, value, next);}// For treeifyBin | 转化为树节点TreeNode&lt;K,V&gt; replacementTreeNode(Node&lt;K,V&gt; p, Node&lt;K,V&gt; next) { return new TreeNode&lt;&gt;(p.hash, p.key, p.value, next);}/** * Reset to initial default state. Called by clone and readObject. * 重置为初始默认状态。 由clone和readObject调用 */void reinitialize() { table = null; entrySet = null; keySet = null; values = null; modCount = 0; threshold = 0; size = 0;}// Callbacks to allow LinkedHashMap post-actions | 允许LinkedHashMap后处理的回调void afterNodeAccess(Node&lt;K,V&gt; p) { }void afterNodeInsertion(boolean evict) { }void afterNodeRemoval(Node&lt;K,V&gt; p) { }// Called only from writeObject, to ensure compatible ordering. | 仅从writeObject调用，以确保兼容的顺序。void internalWriteEntries(java.io.ObjectOutputStream s) throws IOException { Node&lt;K,V&gt;[] tab; if (size &gt; 0 &amp;&amp; (tab = table) != null) { for (int i = 0; i &lt; tab.length; ++i) { for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) { s.writeObject(e.key); s.writeObject(e.value); } } }} Tree bins 树箱>folded123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612/* ------------------------------------------------------------ */// Tree bins/** * Entry for Tree bins. Extends LinkedHashMap.Entry (which in turn * extends Node) so can be used as extension of either regular or * linked node. * 树箱的Entry。 继承LinkedHashMap.Entry（进而扩展Node），因此可以用作常规节点或链接节点的扩展。 */static final class TreeNode&lt;K,V&gt; extends LinkedHashMap.Entry&lt;K,V&gt; { TreeNode&lt;K,V&gt; parent; // red-black tree links TreeNode&lt;K,V&gt; left; TreeNode&lt;K,V&gt; right; TreeNode&lt;K,V&gt; prev; // needed to unlink next upon deletion boolean red; TreeNode(int hash, K key, V val, Node&lt;K,V&gt; next) { super(hash, key, val, next); } /** * Returns root of tree containing this node. * 返回包含此节点的树的根节点 */ final TreeNode&lt;K,V&gt; root() { for (TreeNode&lt;K,V&gt; r = this, p;;) { if ((p = r.parent) == null) return r; r = p; } } /** * Ensures that the given root is the first node of its bin. * 确保给定的根是其bin的第一个节点。 */ static &lt;K,V&gt; void moveRootToFront(Node&lt;K,V&gt;[] tab, TreeNode&lt;K,V&gt; root) { int n; if (root != null &amp;&amp; tab != null &amp;&amp; (n = tab.length) &gt; 0) { int index = (n - 1) &amp; root.hash; TreeNode&lt;K,V&gt; first = (TreeNode&lt;K,V&gt;)tab[index]; if (root != first) { Node&lt;K,V&gt; rn; tab[index] = root; TreeNode&lt;K,V&gt; rp = root.prev; if ((rn = root.next) != null) ((TreeNode&lt;K,V&gt;)rn).prev = rp; if (rp != null) rp.next = rn; if (first != null) first.prev = root; root.next = first; root.prev = null; } assert checkInvariants(root); } } /** * Finds the node starting at root p with the given hash and key. * The kc argument caches comparableClassFor(key) upon first use * comparing keys. * 根据给定的hash和key 从树根节点p开始查找该节点。 * kc参数在首次比较key时会缓存comparableClassFor(key) */ final TreeNode&lt;K,V&gt; find(int h, Object k, Class&lt;?&gt; kc) { TreeNode&lt;K,V&gt; p = this; do { int ph, dir; K pk; TreeNode&lt;K,V&gt; pl = p.left, pr = p.right, q; if ((ph = p.hash) &gt; h) p = pl; else if (ph &lt; h) p = pr; else if ((pk = p.key) == k || (k != null &amp;&amp; k.equals(pk))) return p; else if (pl == null) p = pr; else if (pr == null) p = pl; else if ((kc != null || (kc = comparableClassFor(k)) != null) &amp;&amp; (dir = compareComparables(kc, k, pk)) != 0) p = (dir &lt; 0) ? pl : pr; else if ((q = pr.find(h, k, kc)) != null) return q; else p = pl; } while (p != null); return null; } /** * Calls find for root node. * 调用查找根节点。 */ final TreeNode&lt;K,V&gt; getTreeNode(int h, Object k) { return ((parent != null) ? root() : this).find(h, k, null); } /** * Tie-breaking utility for ordering insertions when equal * hashCodes and non-comparable. We don't require a total * order, just a consistent insertion rule to maintain * equivalence across rebalancings. Tie-breaking further than * necessary simplifies testing a bit. * Tie-breaking程序，用于在hashCodes相等且不可比较时对插入进行排序。 * 我们不需要总的排序，只需一个一致的插入规则即可在重新平衡期间保持等效。 * Tie-breaking比简化测试更有必要。 */ static int tieBreakOrder(Object a, Object b) { int d; if (a == null || b == null || (d = a.getClass().getName(). compareTo(b.getClass().getName())) == 0) d = (System.identityHashCode(a) &lt;= System.identityHashCode(b) ? -1 : 1); return d; } /** * Forms tree of the nodes linked from this node. * 从该节点链接的节点的表单树。- 树化节点：非树节点 -&gt; 树节点 * @return root of tree */ final void treeify(Node&lt;K,V&gt;[] tab) { TreeNode&lt;K,V&gt; root = null; for (TreeNode&lt;K,V&gt; x = this, next; x != null; x = next) { next = (TreeNode&lt;K,V&gt;)x.next; x.left = x.right = null; if (root == null) { x.parent = null; x.red = false; root = x; } else { K k = x.key; int h = x.hash; Class&lt;?&gt; kc = null; for (TreeNode&lt;K,V&gt; p = root;;) { int dir, ph; K pk = p.key; if ((ph = p.hash) &gt; h) dir = -1; else if (ph &lt; h) dir = 1; else if ((kc == null &amp;&amp; (kc = comparableClassFor(k)) == null) || (dir = compareComparables(kc, k, pk)) == 0) dir = tieBreakOrder(k, pk); TreeNode&lt;K,V&gt; xp = p; if ((p = (dir &lt;= 0) ? p.left : p.right) == null) { x.parent = xp; if (dir &lt;= 0) xp.left = x; else xp.right = x; root = balanceInsertion(root, x); break; } } } } moveRootToFront(tab, root); } /** * Returns a list of non-TreeNodes replacing those linked from * this node. * 返回非TreeNode列表，该列表替换从该节点链接的非TreeNode。- 去树化：树节点 -&gt; 非树节点 */ final Node&lt;K,V&gt; untreeify(HashMap&lt;K,V&gt; map) { Node&lt;K,V&gt; hd = null, tl = null; for (Node&lt;K,V&gt; q = this; q != null; q = q.next) { Node&lt;K,V&gt; p = map.replacementNode(q, null); if (tl == null) hd = p; else tl.next = p; tl = p; } return hd; } /** * Tree version of putVal. */ final TreeNode&lt;K,V&gt; putTreeVal(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab, int h, K k, V v) { Class&lt;?&gt; kc = null; boolean searched = false; TreeNode&lt;K,V&gt; root = (parent != null) ? root() : this; for (TreeNode&lt;K,V&gt; p = root;;) { int dir, ph; K pk; if ((ph = p.hash) &gt; h) dir = -1; else if (ph &lt; h) dir = 1; else if ((pk = p.key) == k || (k != null &amp;&amp; k.equals(pk))) return p; else if ((kc == null &amp;&amp; (kc = comparableClassFor(k)) == null) || (dir = compareComparables(kc, k, pk)) == 0) { if (!searched) { TreeNode&lt;K,V&gt; q, ch; searched = true; if (((ch = p.left) != null &amp;&amp; (q = ch.find(h, k, kc)) != null) || ((ch = p.right) != null &amp;&amp; (q = ch.find(h, k, kc)) != null)) return q; } dir = tieBreakOrder(k, pk); } TreeNode&lt;K,V&gt; xp = p; if ((p = (dir &lt;= 0) ? p.left : p.right) == null) { Node&lt;K,V&gt; xpn = xp.next; TreeNode&lt;K,V&gt; x = map.newTreeNode(h, k, v, xpn); if (dir &lt;= 0) xp.left = x; else xp.right = x; xp.next = x; x.parent = x.prev = xp; if (xpn != null) ((TreeNode&lt;K,V&gt;)xpn).prev = x; moveRootToFront(tab, balanceInsertion(root, x)); return null; } } } /** * Removes the given node, that must be present before this call. * This is messier than typical red-black deletion code because we * cannot swap the contents of an interior node with a leaf * successor that is pinned by &quot;next&quot; pointers that are accessible * independently during traversal. So instead we swap the tree * linkages. If the current tree appears to have too few nodes, * the bin is converted back to a plain bin. (The test triggers * somewhere between 2 and 6 nodes, depending on tree structure). * 删除给定节点必须在此调用之前。 * 这比典型的红黑树删除代码更为混乱，因为我们不能将内部节点的内容与叶继承者交换，叶继承者是由在遍历期间可独立访问的“下一个”指针固定的。 * 因此，我们交换树链接。如果当前树的节点似乎太少，则将树箱转换回普通箱。 （该测试触发在2到6个节点之间的某个位置，具体取决于树的结构）。 */ final void removeTreeNode(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab, boolean movable) { int n; if (tab == null || (n = tab.length) == 0) return; int index = (n - 1) &amp; hash; TreeNode&lt;K,V&gt; first = (TreeNode&lt;K,V&gt;)tab[index], root = first, rl; TreeNode&lt;K,V&gt; succ = (TreeNode&lt;K,V&gt;)next, pred = prev; if (pred == null) tab[index] = first = succ; else pred.next = succ; if (succ != null) succ.prev = pred; if (first == null) return; if (root.parent != null) root = root.root(); if (root == null || root.right == null || (rl = root.left) == null || rl.left == null) { tab[index] = first.untreeify(map); // too small return; } TreeNode&lt;K,V&gt; p = this, pl = left, pr = right, replacement; if (pl != null &amp;&amp; pr != null) { TreeNode&lt;K,V&gt; s = pr, sl; while ((sl = s.left) != null) // find successor | 查找继任者 s = sl; boolean c = s.red; s.red = p.red; p.red = c; // swap colors | 交换颜色 TreeNode&lt;K,V&gt; sr = s.right; TreeNode&lt;K,V&gt; pp = p.parent; if (s == pr) { // p was s's direct parent | p是s的直接父级 p.parent = s; s.right = p; } else { TreeNode&lt;K,V&gt; sp = s.parent; if ((p.parent = sp) != null) { if (s == sp.left) sp.left = p; else sp.right = p; } if ((s.right = pr) != null) pr.parent = s; } p.left = null; if ((p.right = sr) != null) sr.parent = p; if ((s.left = pl) != null) pl.parent = s; if ((s.parent = pp) == null) root = s; else if (p == pp.left) pp.left = s; else pp.right = s; if (sr != null) replacement = sr; else replacement = p; } else if (pl != null) replacement = pl; else if (pr != null) replacement = pr; else replacement = p; if (replacement != p) { TreeNode&lt;K,V&gt; pp = replacement.parent = p.parent; if (pp == null) root = replacement; else if (p == pp.left) pp.left = replacement; else pp.right = replacement; p.left = p.right = p.parent = null; } TreeNode&lt;K,V&gt; r = p.red ? root : balanceDeletion(root, replacement); if (replacement == p) { // detach | 分离 TreeNode&lt;K,V&gt; pp = p.parent; p.parent = null; if (pp != null) { if (p == pp.left) pp.left = null; else if (p == pp.right) pp.right = null; } } if (movable) moveRootToFront(tab, r); } /** * Splits nodes in a tree bin into lower and upper tree bins, * or untreeifies if now too small. Called only from resize; * see above discussion about split bits and indices. * 将树箱中的节点拆分为较高和较低的树箱，如果现在太小，则取消树化。仅被resize调用； * 请参阅上面有关拆分位和索引的讨论。 * * @param map the map * @param tab the table for recording bin heads * @param index the index of the table being split * @param bit the bit of hash to split on */ final void split(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab, int index, int bit) { TreeNode&lt;K,V&gt; b = this; // Relink into lo and hi lists, preserving order | 重新链接到lo和hi列表，保留顺序 TreeNode&lt;K,V&gt; loHead = null, loTail = null; TreeNode&lt;K,V&gt; hiHead = null, hiTail = null; int lc = 0, hc = 0; for (TreeNode&lt;K,V&gt; e = b, next; e != null; e = next) { next = (TreeNode&lt;K,V&gt;)e.next; e.next = null; if ((e.hash &amp; bit) == 0) { if ((e.prev = loTail) == null) loHead = e; else loTail.next = e; loTail = e; ++lc; } else { if ((e.prev = hiTail) == null) hiHead = e; else hiTail.next = e; hiTail = e; ++hc; } } if (loHead != null) { if (lc &lt;= UNTREEIFY_THRESHOLD) tab[index] = loHead.untreeify(map); else { tab[index] = loHead; if (hiHead != null) // (else is already treeified) | 其他已经被树化了 loHead.treeify(tab); } } if (hiHead != null) { if (hc &lt;= UNTREEIFY_THRESHOLD) tab[index + bit] = hiHead.untreeify(map); else { tab[index + bit] = hiHead; if (loHead != null) hiHead.treeify(tab); } } } /* ------------------------------------------------------------ */ // Red-black tree methods, all adapted from CLR | 红黑树方法，全部改编自CLR static &lt;K,V&gt; TreeNode&lt;K,V&gt; rotateLeft(TreeNode&lt;K,V&gt; root, TreeNode&lt;K,V&gt; p) { TreeNode&lt;K,V&gt; r, pp, rl; if (p != null &amp;&amp; (r = p.right) != null) { if ((rl = p.right = r.left) != null) rl.parent = p; if ((pp = r.parent = p.parent) == null) (root = r).red = false; else if (pp.left == p) pp.left = r; else pp.right = r; r.left = p; p.parent = r; } return root; } static &lt;K,V&gt; TreeNode&lt;K,V&gt; rotateRight(TreeNode&lt;K,V&gt; root, TreeNode&lt;K,V&gt; p) { TreeNode&lt;K,V&gt; l, pp, lr; if (p != null &amp;&amp; (l = p.left) != null) { if ((lr = p.left = l.right) != null) lr.parent = p; if ((pp = l.parent = p.parent) == null) (root = l).red = false; else if (pp.right == p) pp.right = l; else pp.left = l; l.right = p; p.parent = l; } return root; } static &lt;K,V&gt; TreeNode&lt;K,V&gt; balanceInsertion(TreeNode&lt;K,V&gt; root, TreeNode&lt;K,V&gt; x) { x.red = true; for (TreeNode&lt;K,V&gt; xp, xpp, xppl, xppr;;) { if ((xp = x.parent) == null) { x.red = false; return x; } else if (!xp.red || (xpp = xp.parent) == null) return root; if (xp == (xppl = xpp.left)) { if ((xppr = xpp.right) != null &amp;&amp; xppr.red) { xppr.red = false; xp.red = false; xpp.red = true; x = xpp; } else { if (x == xp.right) { root = rotateLeft(root, x = xp); xpp = (xp = x.parent) == null ? null : xp.parent; } if (xp != null) { xp.red = false; if (xpp != null) { xpp.red = true; root = rotateRight(root, xpp); } } } } else { if (xppl != null &amp;&amp; xppl.red) { xppl.red = false; xp.red = false; xpp.red = true; x = xpp; } else { if (x == xp.left) { root = rotateRight(root, x = xp); xpp = (xp = x.parent) == null ? null : xp.parent; } if (xp != null) { xp.red = false; if (xpp != null) { xpp.red = true; root = rotateLeft(root, xpp); } } } } } } static &lt;K,V&gt; TreeNode&lt;K,V&gt; balanceDeletion(TreeNode&lt;K,V&gt; root, TreeNode&lt;K,V&gt; x) { for (TreeNode&lt;K,V&gt; xp, xpl, xpr;;) { if (x == null || x == root) return root; else if ((xp = x.parent) == null) { x.red = false; return x; } else if (x.red) { x.red = false; return root; } else if ((xpl = xp.left) == x) { if ((xpr = xp.right) != null &amp;&amp; xpr.red) { xpr.red = false; xp.red = true; root = rotateLeft(root, xp); xpr = (xp = x.parent) == null ? null : xp.right; } if (xpr == null) x = xp; else { TreeNode&lt;K,V&gt; sl = xpr.left, sr = xpr.right; if ((sr == null || !sr.red) &amp;&amp; (sl == null || !sl.red)) { xpr.red = true; x = xp; } else { if (sr == null || !sr.red) { if (sl != null) sl.red = false; xpr.red = true; root = rotateRight(root, xpr); xpr = (xp = x.parent) == null ? null : xp.right; } if (xpr != null) { xpr.red = (xp == null) ? false : xp.red; if ((sr = xpr.right) != null) sr.red = false; } if (xp != null) { xp.red = false; root = rotateLeft(root, xp); } x = root; } } } else { // symmetric | 对称的 if (xpl != null &amp;&amp; xpl.red) { xpl.red = false; xp.red = true; root = rotateRight(root, xp); xpl = (xp = x.parent) == null ? null : xp.left; } if (xpl == null) x = xp; else { TreeNode&lt;K,V&gt; sl = xpl.left, sr = xpl.right; if ((sl == null || !sl.red) &amp;&amp; (sr == null || !sr.red)) { xpl.red = true; x = xp; } else { if (sl == null || !sl.red) { if (sr != null) sr.red = false; xpl.red = true; root = rotateLeft(root, xpl); xpl = (xp = x.parent) == null ? null : xp.left; } if (xpl != null) { xpl.red = (xp == null) ? false : xp.red; if ((sl = xpl.left) != null) sl.red = false; } if (xp != null) { xp.red = false; root = rotateRight(root, xp); } x = root; } } } } } /** * Recursive invariant check * 递归不变检查 */ static &lt;K,V&gt; boolean checkInvariants(TreeNode&lt;K,V&gt; t) { TreeNode&lt;K,V&gt; tp = t.parent, tl = t.left, tr = t.right, tb = t.prev, tn = (TreeNode&lt;K,V&gt;)t.next; if (tb != null &amp;&amp; tb.next != t) return false; if (tn != null &amp;&amp; tn.prev != t) return false; if (tp != null &amp;&amp; t != tp.left &amp;&amp; t != tp.right) return false; if (tl != null &amp;&amp; (tl.parent != t || tl.hash &gt; t.hash)) return false; if (tr != null &amp;&amp; (tr.parent != t || tr.hash &lt; t.hash)) return false; if (t.red &amp;&amp; tl != null &amp;&amp; tl.red &amp;&amp; tr != null &amp;&amp; tr.red) return false; if (tl != null &amp;&amp; !checkInvariants(tl)) return false; if (tr != null &amp;&amp; !checkInvariants(tr)) return false; return true; }}","link":"/2020/10/15/source_code/hashmap/"},{"title":"Lock 源码翻译","text":"【尚未完结】**基于JDK1.8** 版权声明>folded1234567891011121314/* * ORACLE PROPRIETARY/CONFIDENTIAL. Use is subject to license terms. * Oracle 专有/机密。 使用须遵守许可条款。 *//* * Written by Doug Lea with assistance from members of JCP JSR-166 * Expert Group and released to the public domain, as explained at * http://creativecommons.org/publicdomain/zero/1.0/ * 由Doug Lea在JCP JSR-166专家组成员的协助下撰写，并已发布到公共领域， * 如http://creativecommons.org/publicdomain/zero/1.0/所述 */package java.util.concurrent.locks;import java.util.concurrent.TimeUnit; 类说明>folded 原123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128/** * {@code Lock} implementations provide more extensive locking * operations than can be obtained using {@code synchronized} methods * and statements. They allow more flexible structuring, may have * quite different properties, and may support multiple associated * {@link Condition} objects. * * &lt;p&gt;A lock is a tool for controlling access to a shared resource by * multiple threads. Commonly, a lock provides exclusive access to a * shared resource: only one thread at a time can acquire the lock and * all access to the shared resource requires that the lock be * acquired first. However, some locks may allow concurrent access to * a shared resource, such as the read lock of a {@link ReadWriteLock}. * * &lt;p&gt;The use of {@code synchronized} methods or statements provides * access to the implicit monitor lock associated with every object, but * forces all lock acquisition and release to occur in a block-structured way: * when multiple locks are acquired they must be released in the opposite * order, and all locks must be released in the same lexical scope in which * they were acquired. * * &lt;p&gt;While the scoping mechanism for {@code synchronized} methods * and statements makes it much easier to program with monitor locks, * and helps avoid many common programming errors involving locks, * there are occasions where you need to work with locks in a more * flexible way. For example, some algorithms for traversing * concurrently accessed data structures require the use of * &amp;quot;hand-over-hand&amp;quot; or &amp;quot;chain locking&amp;quot;: you * acquire the lock of node A, then node B, then release A and acquire * C, then release B and acquire D and so on. Implementations of the * {@code Lock} interface enable the use of such techniques by * allowing a lock to be acquired and released in different scopes, * and allowing multiple locks to be acquired and released in any * order. * * &lt;p&gt;With this increased flexibility comes additional * responsibility. The absence of block-structured locking removes the * automatic release of locks that occurs with {@code synchronized} * methods and statements. In most cases, the following idiom * should be used: * * &lt;pre&gt; {@code * Lock l = ...; * l.lock(); * try { * // access the resource protected by this lock * } finally { * l.unlock(); * }}&lt;/pre&gt; * * When locking and unlocking occur in different scopes, care must be * taken to ensure that all code that is executed while the lock is * held is protected by try-finally or try-catch to ensure that the * lock is released when necessary. * * &lt;p&gt;{@code Lock} implementations provide additional functionality * over the use of {@code synchronized} methods and statements by * providing a non-blocking attempt to acquire a lock ({@link * #tryLock()}), an attempt to acquire the lock that can be * interrupted ({@link #lockInterruptibly}, and an attempt to acquire * the lock that can timeout ({@link #tryLock(long, TimeUnit)}). * * &lt;p&gt;A {@code Lock} class can also provide behavior and semantics * that is quite different from that of the implicit monitor lock, * such as guaranteed ordering, non-reentrant usage, or deadlock * detection. If an implementation provides such specialized semantics * then the implementation must document those semantics. * * &lt;p&gt;Note that {@code Lock} instances are just normal objects and can * themselves be used as the target in a {@code synchronized} statement. * Acquiring the * monitor lock of a {@code Lock} instance has no specified relationship * with invoking any of the {@link #lock} methods of that instance. * It is recommended that to avoid confusion you never use {@code Lock} * instances in this way, except within their own implementation. * * &lt;p&gt;Except where noted, passing a {@code null} value for any * parameter will result in a {@link NullPointerException} being * thrown. * * &lt;h3&gt;Memory Synchronization&lt;/h3&gt; * * &lt;p&gt;All {@code Lock} implementations &lt;em&gt;must&lt;/em&gt; enforce the same * memory synchronization semantics as provided by the built-in monitor * lock, as described in * &lt;a href=&quot;https://docs.oracle.com/javase/specs/jls/se7/html/jls-17.html#jls-17.4&quot;&gt; * The Java Language Specification (17.4 Memory Model)&lt;/a&gt;: * &lt;ul&gt; * &lt;li&gt;A successful {@code lock} operation has the same memory * synchronization effects as a successful &lt;em&gt;Lock&lt;/em&gt; action. * &lt;li&gt;A successful {@code unlock} operation has the same * memory synchronization effects as a successful &lt;em&gt;Unlock&lt;/em&gt; action. * &lt;/ul&gt; * * Unsuccessful locking and unlocking operations, and reentrant * locking/unlocking operations, do not require any memory * synchronization effects. * * &lt;h3&gt;Implementation Considerations&lt;/h3&gt; * * &lt;p&gt;The three forms of lock acquisition (interruptible, * non-interruptible, and timed) may differ in their performance * characteristics, ordering guarantees, or other implementation * qualities. Further, the ability to interrupt the &lt;em&gt;ongoing&lt;/em&gt; * acquisition of a lock may not be available in a given {@code Lock} * class. Consequently, an implementation is not required to define * exactly the same guarantees or semantics for all three forms of * lock acquisition, nor is it required to support interruption of an * ongoing lock acquisition. An implementation is required to clearly * document the semantics and guarantees provided by each of the * locking methods. It must also obey the interruption semantics as * defined in this interface, to the extent that interruption of lock * acquisition is supported: which is either totally, or only on * method entry. * * &lt;p&gt;As interruption generally implies cancellation, and checks for * interruption are often infrequent, an implementation can favor responding * to an interrupt over normal method return. This is true even if it can be * shown that the interrupt occurred after another action may have unblocked * the thread. An implementation should document this behavior. * * @see ReentrantLock * @see Condition * @see ReadWriteLock * * @since 1.5 * @author Doug Lea */ >folded 译123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263/** * 与使用同步方法和语句相比，锁实现提供了更广泛的锁操作。 * 它们允许更灵活的结构，可以具有完全不同的属性，并且可以支持多个关联的Condition(条件)对象。 * * 锁是一种用于控制多个线程对共享资源的访问的工具。 * 通常，锁提供对共享资源的独占访问：一次只能有一个线程可以获取该锁，而对共享资源的所有访问都需要首先获取该锁。 * 但是，某些锁可能允许并发访问共享资源，例如ReadWriteLock的读锁。 * * 使用同步方法或语句可访问与每个对象关联的隐式监视器锁，但会强制所有锁的获取和释放以块结构方式进行： * 当获取多个锁时，它们必须以相反的顺序释放，并且 所有锁必须在获得它们的相同词汇范围内释放。 * * 尽管用于synchronized同步方法和语句的作用域机制使得用监视器锁的编程变得更加容易，并有助于避免许多常见的涉及锁的编程错误， * 但在某些情况下，您需要以更灵活的方式使用锁。 * 例如，某些用于遍历并发访问的数据结构的算法需要使用“移交”或“链锁”：您获取节点A的锁，然后获取节点B的锁，然后释放A并获取C，然后释放B 并获得D等。 * Lock接口的实现通过允许在不同范围内获取和释放锁，并允许以任意顺序获取和释放多个锁，从而启用了此类技术。 * * 灵活性的提高带来了额外的责任。缺少块结构锁定将消除同步方法和语句发生的自动锁定释放。 * 在大多数情况下，应使用以下惯用法： * * Lock l = ...; * l.lock(); * try { * // access the resource protected by this lock * } finally { * l.unlock(); * } * * 当锁定和解锁发生在不同的范围内时，必须小心以确保通过try-finally或try-catch保护持有锁时执行的所有代码， * 以确保在必要时释放锁。 * * Lock实现提供了比synchronized同步方法和语句之外更多的功能。它可以非阻塞的尝试去获取锁(tryLock())，可以获取可被中断的锁lockInterruptibly， * 包括可以设置超时时间的锁(tryLock(long，TimeUnit))。 * * Lock类还可以提供与隐式监视器锁定完全不同的行为和语义，例如保证顺序，不可重用或死锁检测。 * 如果实现提供了这种特殊的语义，则实现必须记录这些语义。 * * 请注意，Lock实例只是普通对象，它们本身可以用作同步语句中的目标。获取Lock实例的监视器锁与调用该实例的任何锁方法没有指定的关系。 * 建议避免混淆，除非在自己的实现中使用，否则不要以这种方式使用Lock实例。 * * 除非另有说明，否则为任何参数传递null值都将引发NullPointerException。 * * 内存同步 * * 所有锁实现必须强制执行与内置监视器锁所提供的相同的内存同步语义，如Java语言规范（17.4内存模型）中所述： * * * * * * 不成功的锁定和解锁操作以及可重入的锁定/解锁操作不需要任何内存同步效果。 * * 实现注意事项 * * 锁获取的三种形式（可中断，不可中断和定时）可能在性能特征，订购保证或其他实现质量上有所不同。 * 此外，在给定的Lock类中，可能无法提供中断正在进行的锁定的功能。因此，不需要为所有三种形式的锁获取定义完全相同的保证或语义的实现， * 也不需要支持正在进行的锁获取的中断。需要一个实现来清楚地记录每个锁定方法提供的语义和保证。 * 在支持锁获取中断的范围内，它还必须服从此接口中定义的中断语义：全部或仅在方法输入时才这样做。 * * @see ReentrantLock * @see Condition * @see ReadWriteLock * * @since 1.5 * @author Doug Lea */ 类主体接口方法>folded lock 获取锁1234567891011121314151617181920212223public interface Lock { /** * Acquires the lock. * 获取锁 * * &lt;p&gt;If the lock is not available then the current thread becomes * disabled for thread scheduling purposes and lies dormant until the * lock has been acquired. * 如果该锁不可用，则出于线程调度目的，当前线程将被禁用，并处于休眠状态，直到获得该锁为止。 * * &lt;p&gt;&lt;b&gt;Implementation Considerations&lt;/b&gt; * 实现注意事项 * * &lt;p&gt;A {@code Lock} implementation may be able to detect erroneous use * of the lock, such as an invocation that would cause deadlock, and * may throw an (unchecked) exception in such circumstances. The * circumstances and the exception type must be documented by that * {@code Lock} implementation. * 锁实现可能能够检测到锁的错误使用，例如可能导致死锁的调用，并且在这种情况下可能引发（未经检查的）异常。 * 该Lock实现必须记录情况和异常类型。 */ void lock(); >folded lockInterruptibly 获取锁，除非当前线程被中断12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * Acquires the lock unless the current thread is * {@linkplain Thread#interrupt interrupted}. * 获取锁，除非当前线程被中断。 * * &lt;p&gt;Acquires the lock if it is available and returns immediately. * 获取锁（如果有）并立即返回。 * * &lt;p&gt;If the lock is not available then the current thread becomes * disabled for thread scheduling purposes and lies dormant until * one of two things happens: * * &lt;ul&gt; * &lt;li&gt;The lock is acquired by the current thread; or * &lt;li&gt;Some other thread {@linkplain Thread#interrupt interrupts} the * current thread, and interruption of lock acquisition is supported. * &lt;/ul&gt; * * &lt;p&gt;If the current thread: * &lt;ul&gt; * &lt;li&gt;has its interrupted status set on entry to this method; or * &lt;li&gt;is {@linkplain Thread#interrupt interrupted} while acquiring the * lock, and interruption of lock acquisition is supported, * &lt;/ul&gt; * then {@link InterruptedException} is thrown and the current thread's * interrupted status is cleared. * * &lt;p&gt;&lt;b&gt;Implementation Considerations&lt;/b&gt; * * &lt;p&gt;The ability to interrupt a lock acquisition in some * implementations may not be possible, and if possible may be an * expensive operation. The programmer should be aware that this * may be the case. An implementation should document when this is * the case. * * &lt;p&gt;An implementation can favor responding to an interrupt over * normal method return. * * &lt;p&gt;A {@code Lock} implementation may be able to detect * erroneous use of the lock, such as an invocation that would * cause deadlock, and may throw an (unchecked) exception in such * circumstances. The circumstances and the exception type must * be documented by that {@code Lock} implementation. * * @throws InterruptedException if the current thread is * interrupted while acquiring the lock (and interruption * of lock acquisition is supported) */void lockInterruptibly() throws InterruptedException; >folded DEFAULT_LOAD_FACTOR 默认负载因子12345/** * The load factor used when none specified in constructor. * 在构造函数中未指定时使用的负载系数。默认0.75 */static final float DEFAULT_LOAD_FACTOR = 0.75f; >folded TREEIFY_THRESHOLD 树化阈值1234567891011/** * The bin count threshold for using a tree rather than list for a * bin. Bins are converted to trees when adding an element to a * bin with at least this many nodes. The value must be greater * than 2 and should be at least 8 to mesh with assumptions in * tree removal about conversion back to plain bins upon * shrinkage. * 选择使用树结构而不是列表结构的计数阈值。桶里元素添加到至少具有这么多时，桶的结构会转换为树结构。 * 该值必须大于2，并且至少是8才能与树删除中的假设（即收缩时转换回原始列表结构的桶）相啮合 */static final int TREEIFY_THRESHOLD = 8; >folded UNTREEIFY_THRESHOLD 去树化阈值1234567/** * The bin count threshold for untreeifying a (split) bin during a * resize operation. Should be less than TREEIFY_THRESHOLD, and at * most 6 to mesh with shrinkage detection under removal. * 在resize操作期间用于去树化（拆分）箱的计数阈值。应小于TREEIFY_THRESHOLD（树化阈值），并且最大为6以与删除时的收缩检测相啮合。 */static final int UNTREEIFY_THRESHOLD = 6; >folded MIN_TREEIFY_CAPACITY 树结构存在时最小table表容量123456789/** * The smallest table capacity for which bins may be treeified. * (Otherwise the table is resized if too many nodes in a bin.) * Should be at least 4 * TREEIFY_THRESHOLD to avoid conflicts * between resizing and treeification thresholds. * 树结构存在的最小表容量。（否则，如果桶中的节点过多，则将调整表的大小 - 增加table数组长度。） * 应至少为 4 * TREEIFY_THRESHOLD，以避免调整大小和树化阈值之间发生冲突。 */static final int MIN_TREEIFY_CAPACITY = 64; 静态内部类>folded Node 普通节点123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * Basic hash bin node, used for most entries. (See below for * TreeNode subclass, and in LinkedHashMap for its Entry subclass.) * 基本哈希箱节点，用于大多数条目。（有关TreeNode子类的信息，请参见下文；有关Entry子类的信息，请参见LinkedHashMap。） * 节点对象包含四个属性：key值的hash值、key值、映射的值value、下一个节点对象 */static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; { final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) { this.hash = hash; this.key = key; this.value = value; this.next = next; } public final K getKey() { return key; } public final V getValue() { return value; } public final String toString() { return key + &quot;=&quot; + value; } public final int hashCode() { return Objects.hashCode(key) ^ Objects.hashCode(value); } public final V setValue(V newValue) { V oldValue = value; value = newValue; return oldValue; } public final boolean equals(Object o) { if (o == this) return true; if (o instanceof Map.Entry) { Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; } return false; }} 静态工具方法>folded hash 计算hash值1234567891011121314151617181920212223242526272829303132333435363738394041424344/* ---------------- Static utilities -------------- *//** * Computes key.hashCode() and spreads (XORs) higher bits of hash * to lower. Because the table uses power-of-two masking, sets of * hashes that vary only in bits above the current mask will * always collide. (Among known examples are sets of Float keys * holding consecutive whole numbers in small tables.) So we * apply a transform that spreads the impact of higher bits * downward. There is a tradeoff between speed, utility, and * quality of bit-spreading. Because many common sets of hashes * are already reasonably distributed (so don't benefit from * spreading), and because we use trees to handle large sets of * collisions in bins, we just XOR some shifted bits in the * cheapest possible way to reduce systematic lossage, as well as * to incorporate impact of the highest bits that would otherwise * never be used in index calculations because of table bounds. * 计算key.hashCode()并将哈希的较高位特征（XOR）扩展到较低位中。 * 由于该表使用2的幂次掩码，因此仅在当前掩码上方的位中发生变化的哈希集将始终发生冲突。 * （众所周知的例子是在小表中包含连续整数的Float键集。）因此，我们应用了一种变换，将向下扩展较高位的影响。 * 在速度，实用性和位扩展质量之间需要权衡。由于许多常见的哈希集已经合理分布（因此无法从扩展中受益），并且由于我们使用树来处理容器中的大量冲突， * 因此我们仅以最便宜的方式对一些移位后的位进行XOR（异或运算），以减少系统损失，以及合并较高位的影响，否则由于表范围的限制，这些位将永远不会在索引计算中使用。 * * 意思就是将高位的二进制特征合并到低位特征中（这么做的原因是后面定位数组下标使用的方法是： * hash &amp; (tab.length-1)，这个二进制运算使得hash高位被屏蔽没有起作用，所以为了保留高位的特征和影响而进行了扩展操作， * 保留高位特征可以减小hash碰撞）。 * 示例1：高低位异或运算 * h=key.hashcode() 1111 1101 1101 1111 0101 1101 0010 1001 * ^ * h &gt;&gt;&gt; 16 0000 0000 0000 0000 1111 1101 1101 1111 * ———————————————————————————————————————————————————————— * h ^ (h &gt;&gt;&gt; 16) 1111 1101 1101 1111 1010 0000 1111 0110 * * 示例2：定位元素所处的数组位置（假设此时数组长度=16） * hash 1111 1101 1101 1111 1010 0000 1111 0110 * &amp; * 16-1 0000 0000 0000 0000 0000 0000 0000 1111 * ———————————————————————————————————————————————————————— * hash &amp; (16-1) 0000 0000 0000 0000 0000 0000 0000 0110 */static final int hash(Object key) { int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);} >folded comparableClassFor123456789101112131415161718192021222324/** * Returns x's Class if it is of the form &quot;class C implements * Comparable&lt;C&gt;&quot;, else null. * 返回 x 的 class 如果 x instanceof Comparable * 否则返回 null */static Class&lt;?&gt; comparableClassFor(Object x) { if (x instanceof Comparable) { Class&lt;?&gt; c; Type[] ts, as; Type t; ParameterizedType p; if ((c = x.getClass()) == String.class) // bypass checks return c; if ((ts = c.getGenericInterfaces()) != null) { for (int i = 0; i &lt; ts.length; ++i) { if (((t = ts[i]) instanceof ParameterizedType) &amp;&amp; ((p = (ParameterizedType)t).getRawType() == Comparable.class) &amp;&amp; (as = p.getActualTypeArguments()) != null &amp;&amp; as.length == 1 &amp;&amp; as[0] == c) // type arg is c return c; } } } return null;} >folded compareComparables123456789/** * Returns k.compareTo(x) if x matches kc (k's screened comparable * class), else 0. */@SuppressWarnings({&quot;rawtypes&quot;,&quot;unchecked&quot;}) // for cast to Comparablestatic int compareComparables(Class&lt;?&gt; kc, Object k, Object x) { return (x == null || x.getClass() != kc ? 0 : ((Comparable)k).compareTo(x));} >folded tableSizeFor 生成数组长度值12345678910111213/** * Returns a power of two size for the given target capacity. * 对于给定的目标容量，返回一个2的次幂的值 */static final int tableSizeFor(int cap) { int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;} 成员属性>folded table 数组123456789101112/* ---------------- Fields -------------- *//** * The table, initialized on first use, and resized as * necessary. When allocated, length is always a power of two. * (We also tolerate length zero in some operations to allow * bootstrapping mechanics that are currently not needed.) * 该table在首次使用时初始化，并根据需要调整大小。 * 分配时，长度始终是2的幂。（在某些操作中，我们还允许长度为零，以允许使用当前不需要的引导机制。） * transient修饰，该属性值不会被序列化 */transient Node&lt;K,V&gt;[] table; >folded entrySet123456/** * Holds cached entrySet(). Note that AbstractMap fields are used * for keySet() and values(). * 保存缓存的entrySet() 注意，AbstractMap字段用于keySet()和values()。 */transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet; >folded size12345/** * The number of key-value mappings contained in this map. * 此map中包含的键-值映射数。 */transient int size; >folded modCount HashMap结构修改次数12345678910/** * The number of times this HashMap has been structurally modified * Structural modifications are those that change the number of mappings in * the HashMap or otherwise modify its internal structure (e.g., * rehash). This field is used to make iterators on Collection-views of * the HashMap fail-fast. (See ConcurrentModificationException). * 对该HashMap进行结构修改的次数，结构修改是指更改HashMap中映射次数或以其他方式修改其内部结构（例如，重新哈希）的修改。 * 此字段用于使HashMap的Collection-view上的迭代器快速失败。 （请参见ConcurrentModificationException）。 */transient int modCount; >folded threshold12345678910/** * The next size value at which to resize (capacity * load factor). * resize时下一个大小的值（容量 * 负载因子） * @serial */// (The javadoc description is true upon serialization.// Additionally, if the table array has not been allocated, this// field holds the initial array capacity, or zero signifying// DEFAULT_INITIAL_CAPACITY.)int threshold; >folded loadFactor 负载因子123456/** * The load factor for the hash table. * 哈希表的负载因子 * @serial */final float loadFactor; 成员方法>folded HashMap 构造方法1（初始容量，负载因子）1234567891011121314151617181920212223/* ---------------- Public operations -------------- *//** * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the specified initial * capacity and load factor. * * @param initialCapacity the initial capacity * @param loadFactor the load factor * @throws IllegalArgumentException if the initial capacity is negative * or the load factor is nonpositive */public HashMap(int initialCapacity, float loadFactor) { if (initialCapacity &lt; 0) throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(&quot;Illegal load factor: &quot; + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity);} >folded HashMap 构造方法2（初始容量）12345678910/** * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the specified initial * capacity and the default load factor (0.75). * * @param initialCapacity the initial capacity. * @throws IllegalArgumentException if the initial capacity is negative. */public HashMap(int initialCapacity) { this(initialCapacity, DEFAULT_LOAD_FACTOR);} >folded HashMap 构造方法312345678/** * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the default initial capacity * (16) and the default load factor (0.75). * 默认的初始容量（16）和默认的负载因子（0.75） */public HashMap() { this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted} >folded HashMap 构造方法4（Map类型对象）12345678910111213/** * Constructs a new &lt;tt&gt;HashMap&lt;/tt&gt; with the same mappings as the * specified &lt;tt&gt;Map&lt;/tt&gt;. The &lt;tt&gt;HashMap&lt;/tt&gt; is created with * default load factor (0.75) and an initial capacity sufficient to * hold the mappings in the specified &lt;tt&gt;Map&lt;/tt&gt;. * * @param m the map whose mappings are to be placed in this map * @throws NullPointerException if the specified map is null */public HashMap(Map&lt;? extends K, ? extends V&gt; m) { this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false);} >folded putMapEntries 将传入的map的元素全部put进去123456789101112131415161718192021222324252627/** * Implements Map.putAll and Map constructor * 实现了 Map.putAll 和 Map的构造器 * * @param m the map * @param evict false when initially constructing this map, else * true (relayed to method afterNodeInsertion). */final void putMapEntries(Map&lt;? extends K, ? extends V&gt; m, boolean evict) { int s = m.size(); if (s &gt; 0) { if (table == null) { // pre-size float ft = ((float)s / loadFactor) + 1.0F; int t = ((ft &lt; (float)MAXIMUM_CAPACITY) ? (int)ft : MAXIMUM_CAPACITY); if (t &gt; threshold) threshold = tableSizeFor(t); } else if (s &gt; threshold) resize(); for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) { K key = e.getKey(); V value = e.getValue(); putVal(hash(key), key, value, false, evict); } }} >folded size 返回键-值映射数量12345678/** * Returns the number of key-value mappings in this map. * * @return the number of key-value mappings in this map */public int size() { return size;} >folded isEmpty 返回映射数是否为012345678/** * Returns &lt;tt&gt;true&lt;/tt&gt; if this map contains no key-value mappings. * * @return &lt;tt&gt;true&lt;/tt&gt; if this map contains no key-value mappings */public boolean isEmpty() { return size == 0;} >folded get 根据key获取value123456789101112131415161718192021/** * Returns the value to which the specified key is mapped, * or {@code null} if this map contains no mapping for the key. * * &lt;p&gt;More formally, if this map contains a mapping from a key * {@code k} to a value {@code v} such that {@code (key==null ? k==null : * key.equals(k))}, then this method returns {@code v}; otherwise * it returns {@code null}. (There can be at most one such mapping.) * * &lt;p&gt;A return value of {@code null} does not &lt;i&gt;necessarily&lt;/i&gt; * indicate that the map contains no mapping for the key; it's also * possible that the map explicitly maps the key to {@code null}. * The {@link #containsKey containsKey} operation may be used to * distinguish these two cases. * * @see #put(Object, Object) */public V get(Object key) { Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;} >folded getNode 根据hash值和key获取Node节点（Node/TreeNode）1234567891011121314151617181920212223242526/** * Implements Map.get and related methods * * @param hash hash for key * @param key the key * @return the node, or null if none */final Node&lt;K,V&gt; getNode(int hash, Object key) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) { if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) { if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do { if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; } while ((e = e.next) != null); } } return null;} >folded containsKey 返回map是否包含此键1234567891011/** * Returns &lt;tt&gt;true&lt;/tt&gt; if this map contains a mapping for the * specified key. * * @param key The key whose presence in this map is to be tested * @return &lt;tt&gt;true&lt;/tt&gt; if this map contains a mapping for the specified * key. */public boolean containsKey(Object key) { return getNode(hash(key), key) != null;} >folded put 放元素（key，value）12345678910111213141516/** * Associates the specified value with the specified key in this map. * If the map previously contained a mapping for the key, the old * value is replaced. * 将指定值与该映射中的指定键相关联。如果该映射先前包含该键的映射，则替换旧值 * * @param key key with which the specified value is to be associated * @param value value to be associated with the specified key * @return the previous value associated with &lt;tt&gt;key&lt;/tt&gt;, or * &lt;tt&gt;null&lt;/tt&gt; if there was no mapping for &lt;tt&gt;key&lt;/tt&gt;. * (A &lt;tt&gt;null&lt;/tt&gt; return can also indicate that the map * previously associated &lt;tt&gt;null&lt;/tt&gt; with &lt;tt&gt;key&lt;/tt&gt;.) */public V put(K key, V value) { return putVal(hash(key), key, value, false, true);} >folded putVal 具体put方法的实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * Implements Map.put and related methods * * @param hash hash for key * @param key the key * @param value the value to put * @param onlyIfAbsent if true, don't change existing value * @param evict if false, the table is in creation mode. * @return previous value, or null if none */final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else { Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else { for (int binCount = 0; ; ++binCount) { if ((e = p.next) == null) { p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; } if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; } } if (e != null) { // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; } } ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;} >folded resize 重建table表。初始化或2倍扩容12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182/** * Initializes or doubles table size. If null, allocates in * accord with initial capacity target held in field threshold. * Otherwise, because we are using power-of-two expansion, the * elements from each bin must either stay at same index, or move * with a power of two offset in the new table. * * @return the table */final Node&lt;K,V&gt;[] resize() { Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) { if (oldCap &gt;= MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return oldTab; } else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold } else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else { // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); } if (newThr == 0) { float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); } threshold = newThr; @SuppressWarnings({&quot;rawtypes&quot;,&quot;unchecked&quot;}) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) { for (int j = 0; j &lt; oldCap; ++j) { Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) { oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else { // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do { next = e.next; if ((e.hash &amp; oldCap) == 0) { if (loTail == null) loHead = e; else loTail.next = e; loTail = e; } else { if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; } } while ((e = next) != null); if (loTail != null) { loTail.next = null; newTab[j] = loHead; } if (hiTail != null) { hiTail.next = null; newTab[j + oldCap] = hiHead; } } } } } return newTab;} >folded treeifyBin 树化给定hash值对应的桶所有元素1234567891011121314151617181920212223242526/** * Replaces all linked nodes in bin at index for given hash unless * table is too small, in which case resizes instead. * 树化给定hash值对应的桶所有元素，除非table表太小 - tab.length &lt; MIN_TREEIFY_CAPACITY。 * table表太小的情况就进行一遍resize表重建。 */final void treeifyBin(Node&lt;K,V&gt;[] tab, int hash) { int n, index; Node&lt;K,V&gt; e; if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) resize(); else if ((e = tab[index = (n - 1) &amp; hash]) != null) { TreeNode&lt;K,V&gt; hd = null, tl = null; do { TreeNode&lt;K,V&gt; p = replacementTreeNode(e, null); if (tl == null) hd = p; else { p.prev = tl; tl.next = p; } tl = p; } while ((e = e.next) != null); if ((tab[index] = hd) != null) hd.treeify(tab); }} >folded putAll 将传入的map的元素全部put进去1234567891011/** * Copies all of the mappings from the specified map to this map. * These mappings will replace any mappings that this map had for * any of the keys currently in the specified map. * * @param m mappings to be stored in this map * @throws NullPointerException if the specified map is null */public void putAll(Map&lt;? extends K, ? extends V&gt; m) { putMapEntries(m, true);} >folded remove 删除指定键的映射1234567891011121314/** * Removes the mapping for the specified key from this map if present. * 如果存在，则从此map中删除指定键的映射。 * @param key key whose mapping is to be removed from the map * @return the previous value associated with &lt;tt&gt;key&lt;/tt&gt;, or * &lt;tt&gt;null&lt;/tt&gt; if there was no mapping for &lt;tt&gt;key&lt;/tt&gt;. * (A &lt;tt&gt;null&lt;/tt&gt; return can also indicate that the map * previously associated &lt;tt&gt;null&lt;/tt&gt; with &lt;tt&gt;key&lt;/tt&gt;.) */public V remove(Object key) { Node&lt;K,V&gt; e; return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value;} >folded removeNode 删除指定键的节点1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * Implements Map.remove and related methods * * @param hash hash for key * @param key the key * @param value the value to match if matchValue, else ignored * @param matchValue if true only remove if value is equal * @param movable if false do not move other nodes while removing * @return the node, or null if none */final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) { Node&lt;K,V&gt; node = null, e; K k; V v; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; else if ((e = p.next) != null) { if (p instanceof TreeNode) node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); else { do { if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) { node = e; break; } p = e; } while ((e = e.next) != null); } } if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) { if (node instanceof TreeNode) ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); else if (node == p) tab[index] = node.next; else p.next = node.next; ++modCount; --size; afterNodeRemoval(node); return node; } } return null;} >folded clear 删除全部键值映射12345678910111213/** * Removes all of the mappings from this map. * The map will be empty after this call returns. */public void clear() { Node&lt;K,V&gt;[] tab; modCount++; if ((tab = table) != null &amp;&amp; size &gt; 0) { size = 0; for (int i = 0; i &lt; tab.length; ++i) tab[i] = null; }} >folded containsValue 判断是否包含此值123456789101112131415161718192021/** * Returns &lt;tt&gt;true&lt;/tt&gt; if this map maps one or more keys to the * specified value. * * @param value value whose presence in this map is to be tested * @return &lt;tt&gt;true&lt;/tt&gt; if this map maps one or more keys to the * specified value */public boolean containsValue(Object value) { Node&lt;K,V&gt;[] tab; V v; if ((tab = table) != null &amp;&amp; size &gt; 0) { for (int i = 0; i &lt; tab.length; ++i) { for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) { if ((v = e.value) == value || (value != null &amp;&amp; value.equals(v))) return true; } } } return false;} >folded keySet 返回map包含的所有key值set集合12345678910111213141516171819/** * Returns a {@link Set} view of the keys contained in this map. * The set is backed by the map, so changes to the map are * reflected in the set, and vice-versa. If the map is modified * while an iteration over the set is in progress (except through * the iterator's own &lt;tt&gt;remove&lt;/tt&gt; operation), the results of * the iteration are undefined. The set supports element removal, * which removes the corresponding mapping from the map, via the * &lt;tt&gt;Iterator.remove&lt;/tt&gt;, &lt;tt&gt;Set.remove&lt;/tt&gt;, * &lt;tt&gt;removeAll&lt;/tt&gt;, &lt;tt&gt;retainAll&lt;/tt&gt;, and &lt;tt&gt;clear&lt;/tt&gt; * operations. It does not support the &lt;tt&gt;add&lt;/tt&gt; or &lt;tt&gt;addAll&lt;/tt&gt; * operations. * * @return a set view of the keys contained in this map */public Set&lt;K&gt; keySet() { Set&lt;K&gt; ks; return (ks = keySet) == null ? (keySet = new KeySet()) : ks;} KeySet内部类>folded1234567891011121314151617181920212223242526final class KeySet extends AbstractSet&lt;K&gt; { public final int size() { return size; } public final void clear() { HashMap.this.clear(); } public final Iterator&lt;K&gt; iterator() { return new KeyIterator(); } public final boolean contains(Object o) { return containsKey(o); } public final boolean remove(Object key) { return removeNode(hash(key), key, null, false, true) != null; } public final Spliterator&lt;K&gt; spliterator() { return new KeySpliterator&lt;&gt;(HashMap.this, 0, -1, 0, 0); } public final void forEach(Consumer&lt;? super K&gt; action) { Node&lt;K,V&gt;[] tab; if (action == null) throw new NullPointerException(); if (size &gt; 0 &amp;&amp; (tab = table) != null) { int mc = modCount; for (int i = 0; i &lt; tab.length; ++i) { for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) action.accept(e.key); } if (modCount != mc) throw new ConcurrentModificationException(); } }} >folded values 返回map中所有value的集合12345678910111213141516171819/** * Returns a {@link Collection} view of the values contained in this map. * The collection is backed by the map, so changes to the map are * reflected in the collection, and vice-versa. If the map is * modified while an iteration over the collection is in progress * (except through the iterator's own &lt;tt&gt;remove&lt;/tt&gt; operation), * the results of the iteration are undefined. The collection * supports element removal, which removes the corresponding * mapping from the map, via the &lt;tt&gt;Iterator.remove&lt;/tt&gt;, * &lt;tt&gt;Collection.remove&lt;/tt&gt;, &lt;tt&gt;removeAll&lt;/tt&gt;, * &lt;tt&gt;retainAll&lt;/tt&gt; and &lt;tt&gt;clear&lt;/tt&gt; operations. It does not * support the &lt;tt&gt;add&lt;/tt&gt; or &lt;tt&gt;addAll&lt;/tt&gt; operations. * * @return a view of the values contained in this map */public Collection&lt;V&gt; values() { Collection&lt;V&gt; vs; return (vs = values) == null ? (values = new Values()) : vs;} Values内部类>folded1234567891011121314151617181920212223final class Values extends AbstractCollection&lt;V&gt; { public final int size() { return size; } public final void clear() { HashMap.this.clear(); } public final Iterator&lt;V&gt; iterator() { return new ValueIterator(); } public final boolean contains(Object o) { return containsValue(o); } public final Spliterator&lt;V&gt; spliterator() { return new ValueSpliterator&lt;&gt;(HashMap.this, 0, -1, 0, 0); } public final void forEach(Consumer&lt;? super V&gt; action) { Node&lt;K,V&gt;[] tab; if (action == null) throw new NullPointerException(); if (size &gt; 0 &amp;&amp; (tab = table) != null) { int mc = modCount; for (int i = 0; i &lt; tab.length; ++i) { for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) action.accept(e.value); } if (modCount != mc) throw new ConcurrentModificationException(); } }} >folded entrySet 返回map包含的键值映射集合1234567891011121314151617181920/** * Returns a {@link Set} view of the mappings contained in this map. * The set is backed by the map, so changes to the map are * reflected in the set, and vice-versa. If the map is modified * while an iteration over the set is in progress (except through * the iterator's own &lt;tt&gt;remove&lt;/tt&gt; operation, or through the * &lt;tt&gt;setValue&lt;/tt&gt; operation on a map entry returned by the * iterator) the results of the iteration are undefined. The set * supports element removal, which removes the corresponding * mapping from the map, via the &lt;tt&gt;Iterator.remove&lt;/tt&gt;, * &lt;tt&gt;Set.remove&lt;/tt&gt;, &lt;tt&gt;removeAll&lt;/tt&gt;, &lt;tt&gt;retainAll&lt;/tt&gt; and * &lt;tt&gt;clear&lt;/tt&gt; operations. It does not support the * &lt;tt&gt;add&lt;/tt&gt; or &lt;tt&gt;addAll&lt;/tt&gt; operations. * * @return a set view of the mappings contained in this map */public Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet() { Set&lt;Map.Entry&lt;K,V&gt;&gt; es; return (es = entrySet) == null ? (entrySet = new EntrySet()) : es;} EntrySet内部类>folded1234567891011121314151617181920212223242526272829303132333435363738394041final class EntrySet extends AbstractSet&lt;Map.Entry&lt;K,V&gt;&gt; { public final int size() { return size; } public final void clear() { HashMap.this.clear(); } public final Iterator&lt;Map.Entry&lt;K,V&gt;&gt; iterator() { return new EntryIterator(); } public final boolean contains(Object o) { if (!(o instanceof Map.Entry)) return false; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;) o; Object key = e.getKey(); Node&lt;K,V&gt; candidate = getNode(hash(key), key); return candidate != null &amp;&amp; candidate.equals(e); } public final boolean remove(Object o) { if (o instanceof Map.Entry) { Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;) o; Object key = e.getKey(); Object value = e.getValue(); return removeNode(hash(key), key, value, true, true) != null; } return false; } public final Spliterator&lt;Map.Entry&lt;K,V&gt;&gt; spliterator() { return new EntrySpliterator&lt;&gt;(HashMap.this, 0, -1, 0, 0); } public final void forEach(Consumer&lt;? super Map.Entry&lt;K,V&gt;&gt; action) { Node&lt;K,V&gt;[] tab; if (action == null) throw new NullPointerException(); if (size &gt; 0 &amp;&amp; (tab = table) != null) { int mc = modCount; for (int i = 0; i &lt; tab.length; ++i) { for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) action.accept(e); } if (modCount != mc) throw new ConcurrentModificationException(); } }} 重写JDK8 Map扩展方法>folded123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260// Overrides of JDK8 Map extension methods@Overridepublic V getOrDefault(Object key, V defaultValue) { Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? defaultValue : e.value;}@Overridepublic V putIfAbsent(K key, V value) { return putVal(hash(key), key, value, true, true);}@Overridepublic boolean remove(Object key, Object value) { return removeNode(hash(key), key, value, true, true) != null;}@Overridepublic boolean replace(K key, V oldValue, V newValue) { Node&lt;K,V&gt; e; V v; if ((e = getNode(hash(key), key)) != null &amp;&amp; ((v = e.value) == oldValue || (v != null &amp;&amp; v.equals(oldValue)))) { e.value = newValue; afterNodeAccess(e); return true; } return false;}@Overridepublic V replace(K key, V value) { Node&lt;K,V&gt; e; if ((e = getNode(hash(key), key)) != null) { V oldValue = e.value; e.value = value; afterNodeAccess(e); return oldValue; } return null;}@Overridepublic V computeIfAbsent(K key, Function&lt;? super K, ? extends V&gt; mappingFunction) { if (mappingFunction == null) throw new NullPointerException(); int hash = hash(key); Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first; int n, i; int binCount = 0; TreeNode&lt;K,V&gt; t = null; Node&lt;K,V&gt; old = null; if (size &gt; threshold || (tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((first = tab[i = (n - 1) &amp; hash]) != null) { if (first instanceof TreeNode) old = (t = (TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); else { Node&lt;K,V&gt; e = first; K k; do { if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) { old = e; break; } ++binCount; } while ((e = e.next) != null); } V oldValue; if (old != null &amp;&amp; (oldValue = old.value) != null) { afterNodeAccess(old); return oldValue; } } V v = mappingFunction.apply(key); if (v == null) { return null; } else if (old != null) { old.value = v; afterNodeAccess(old); return v; } else if (t != null) t.putTreeVal(this, tab, hash, key, v); else { tab[i] = newNode(hash, key, v, first); if (binCount &gt;= TREEIFY_THRESHOLD - 1) treeifyBin(tab, hash); } ++modCount; ++size; afterNodeInsertion(true); return v;}public V computeIfPresent(K key, BiFunction&lt;? super K, ? super V, ? extends V&gt; remappingFunction) { if (remappingFunction == null) throw new NullPointerException(); Node&lt;K,V&gt; e; V oldValue; int hash = hash(key); if ((e = getNode(hash, key)) != null &amp;&amp; (oldValue = e.value) != null) { V v = remappingFunction.apply(key, oldValue); if (v != null) { e.value = v; afterNodeAccess(e); return v; } else removeNode(hash, key, null, false, true); } return null;}@Overridepublic V compute(K key, BiFunction&lt;? super K, ? super V, ? extends V&gt; remappingFunction) { if (remappingFunction == null) throw new NullPointerException(); int hash = hash(key); Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first; int n, i; int binCount = 0; TreeNode&lt;K,V&gt; t = null; Node&lt;K,V&gt; old = null; if (size &gt; threshold || (tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((first = tab[i = (n - 1) &amp; hash]) != null) { if (first instanceof TreeNode) old = (t = (TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); else { Node&lt;K,V&gt; e = first; K k; do { if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) { old = e; break; } ++binCount; } while ((e = e.next) != null); } } V oldValue = (old == null) ? null : old.value; V v = remappingFunction.apply(key, oldValue); if (old != null) { if (v != null) { old.value = v; afterNodeAccess(old); } else removeNode(hash, key, null, false, true); } else if (v != null) { if (t != null) t.putTreeVal(this, tab, hash, key, v); else { tab[i] = newNode(hash, key, v, first); if (binCount &gt;= TREEIFY_THRESHOLD - 1) treeifyBin(tab, hash); } ++modCount; ++size; afterNodeInsertion(true); } return v;}@Overridepublic V merge(K key, V value, BiFunction&lt;? super V, ? super V, ? extends V&gt; remappingFunction) { if (value == null) throw new NullPointerException(); if (remappingFunction == null) throw new NullPointerException(); int hash = hash(key); Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first; int n, i; int binCount = 0; TreeNode&lt;K,V&gt; t = null; Node&lt;K,V&gt; old = null; if (size &gt; threshold || (tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((first = tab[i = (n - 1) &amp; hash]) != null) { if (first instanceof TreeNode) old = (t = (TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); else { Node&lt;K,V&gt; e = first; K k; do { if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) { old = e; break; } ++binCount; } while ((e = e.next) != null); } } if (old != null) { V v; if (old.value != null) v = remappingFunction.apply(old.value, value); else v = value; if (v != null) { old.value = v; afterNodeAccess(old); } else removeNode(hash, key, null, false, true); return v; } if (value != null) { if (t != null) t.putTreeVal(this, tab, hash, key, value); else { tab[i] = newNode(hash, key, value, first); if (binCount &gt;= TREEIFY_THRESHOLD - 1) treeifyBin(tab, hash); } ++modCount; ++size; afterNodeInsertion(true); } return value;}@Overridepublic void forEach(BiConsumer&lt;? super K, ? super V&gt; action) { Node&lt;K,V&gt;[] tab; if (action == null) throw new NullPointerException(); if (size &gt; 0 &amp;&amp; (tab = table) != null) { int mc = modCount; for (int i = 0; i &lt; tab.length; ++i) { for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) action.accept(e.key, e.value); } if (modCount != mc) throw new ConcurrentModificationException(); }}@Overridepublic void replaceAll(BiFunction&lt;? super K, ? super V, ? extends V&gt; function) { Node&lt;K,V&gt;[] tab; if (function == null) throw new NullPointerException(); if (size &gt; 0 &amp;&amp; (tab = table) != null) { int mc = modCount; for (int i = 0; i &lt; tab.length; ++i) { for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) { e.value = function.apply(e.key, e.value); } } if (modCount != mc) throw new ConcurrentModificationException(); }} clone 和 序列化方法>folded clone123456789101112131415161718192021222324/* ------------------------------------------------------------ */// Cloning and serialization/** * Returns a shallow copy of this &lt;tt&gt;HashMap&lt;/tt&gt; instance: the keys and * values themselves are not cloned. * 返回此HashMap实例的浅副本：键和值本身不会被克隆。 * * @return a shallow copy of this map */@SuppressWarnings(&quot;unchecked&quot;)@Overridepublic Object clone() { HashMap&lt;K,V&gt; result; try { result = (HashMap&lt;K,V&gt;)super.clone(); } catch (CloneNotSupportedException e) { // this shouldn't happen, since we are Cloneable throw new InternalError(e); } result.reinitialize(); result.putMapEntries(this, false); return result;} >folded serialization 用于序列化的一些方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576// These methods are also used when serializing HashSetsfinal float loadFactor() { return loadFactor; }final int capacity() { return (table != null) ? table.length : (threshold &gt; 0) ? threshold : DEFAULT_INITIAL_CAPACITY;}/** * Save the state of the &lt;tt&gt;HashMap&lt;/tt&gt; instance to a stream (i.e., * serialize it). * 将HashMap实例的状态保存到流中（即序列化它）。 * * @serialData The &lt;i&gt;capacity&lt;/i&gt; of the HashMap (the length of the * bucket array) is emitted (int), followed by the * &lt;i&gt;size&lt;/i&gt; (an int, the number of key-value * mappings), followed by the key (Object) and value (Object) * for each key-value mapping. The key-value mappings are * emitted in no particular order. */private void writeObject(java.io.ObjectOutputStream s) throws IOException { int buckets = capacity(); // Write out the threshold, loadfactor, and any hidden stuff s.defaultWriteObject(); s.writeInt(buckets); s.writeInt(size); internalWriteEntries(s);}/** * Reconstitute the {@code HashMap} instance from a stream (i.e., * deserialize it). * 从流中重建HashMap实例（即反序列化它）。 */private void readObject(java.io.ObjectInputStream s) throws IOException, ClassNotFoundException { // Read in the threshold (ignored), loadfactor, and any hidden stuff s.defaultReadObject(); reinitialize(); if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new InvalidObjectException(&quot;Illegal load factor: &quot; + loadFactor); s.readInt(); // Read and ignore number of buckets int mappings = s.readInt(); // Read number of mappings (size) if (mappings &lt; 0) throw new InvalidObjectException(&quot;Illegal mappings count: &quot; + mappings); else if (mappings &gt; 0) { // (if zero, use defaults) // Size the table using given load factor only if within // range of 0.25...4.0 float lf = Math.min(Math.max(0.25f, loadFactor), 4.0f); float fc = (float)mappings / lf + 1.0f; int cap = ((fc &lt; DEFAULT_INITIAL_CAPACITY) ? DEFAULT_INITIAL_CAPACITY : (fc &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : tableSizeFor((int)fc)); float ft = (float)cap * lf; threshold = ((cap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; MAXIMUM_CAPACITY) ? (int)ft : Integer.MAX_VALUE); @SuppressWarnings({&quot;rawtypes&quot;,&quot;unchecked&quot;}) Node&lt;K,V&gt;[] tab = (Node&lt;K,V&gt;[])new Node[cap]; table = tab; // Read the keys and values, and put the mappings in the HashMap for (int i = 0; i &lt; mappings; i++) { @SuppressWarnings(&quot;unchecked&quot;) K key = (K) s.readObject(); @SuppressWarnings(&quot;unchecked&quot;) V value = (V) s.readObject(); putVal(hash(key), key, value, false, false); } }} iterators 迭代方法>folded HashIterator hash迭代器抽象内部类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/* ------------------------------------------------------------ */// iteratorsabstract class HashIterator { Node&lt;K,V&gt; next; // next entry to return Node&lt;K,V&gt; current; // current entry int expectedModCount; // for fast-fail int index; // current slot HashIterator() { expectedModCount = modCount; Node&lt;K,V&gt;[] t = table; current = next = null; index = 0; if (t != null &amp;&amp; size &gt; 0) { // advance to first entry do {} while (index &lt; t.length &amp;&amp; (next = t[index++]) == null); } } public final boolean hasNext() { return next != null; } final Node&lt;K,V&gt; nextNode() { Node&lt;K,V&gt;[] t; Node&lt;K,V&gt; e = next; if (modCount != expectedModCount) throw new ConcurrentModificationException(); if (e == null) throw new NoSuchElementException(); if ((next = (current = e).next) == null &amp;&amp; (t = table) != null) { do {} while (index &lt; t.length &amp;&amp; (next = t[index++]) == null); } return e; } public final void remove() { Node&lt;K,V&gt; p = current; if (p == null) throw new IllegalStateException(); if (modCount != expectedModCount) throw new ConcurrentModificationException(); current = null; K key = p.key; removeNode(hash(key), key, null, false, false); expectedModCount = modCount; }} >folded HashIterator的三个子类：key、value、映射迭代器1234567891011121314final class KeyIterator extends HashIterator implements Iterator&lt;K&gt; { public final K next() { return nextNode().key; }}final class ValueIterator extends HashIterator implements Iterator&lt;V&gt; { public final V next() { return nextNode().value; }}final class EntryIterator extends HashIterator implements Iterator&lt;Map.Entry&lt;K,V&gt;&gt; { public final Map.Entry&lt;K,V&gt; next() { return nextNode(); }} spliterators 分离器>folded HashMapSpliterator分离器静态内部类1234567891011121314151617181920212223242526272829303132333435363738/* ------------------------------------------------------------ */// spliteratorsstatic class HashMapSpliterator&lt;K,V&gt; { final HashMap&lt;K,V&gt; map; Node&lt;K,V&gt; current; // current node | 当前节点 int index; // current index, modified on advance/split | 当前索引，在 advance/split 时修改 int fence; // one past last index | 最后一个索引 int est; // size estimate | 预估大小 int expectedModCount; // for comodification checks | 预期修改数，用于修改检查 HashMapSpliterator(HashMap&lt;K,V&gt; m, int origin, int fence, int est, int expectedModCount) { this.map = m; this.index = origin; this.fence = fence; this.est = est; this.expectedModCount = expectedModCount; } final int getFence() { // initialize fence and size on first use | 第一次使用时初始化fence和est、expectedModCount int hi; if ((hi = fence) &lt; 0) { HashMap&lt;K,V&gt; m = map; est = m.size; expectedModCount = m.modCount; Node&lt;K,V&gt;[] tab = m.table; hi = fence = (tab == null) ? 0 : tab.length; } return hi; } public final long estimateSize() { getFence(); // force init return (long) est; }} >folded KeySpliterator分离器1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071static final class KeySpliterator&lt;K,V&gt; extends HashMapSpliterator&lt;K,V&gt; implements Spliterator&lt;K&gt; { KeySpliterator(HashMap&lt;K,V&gt; m, int origin, int fence, int est, int expectedModCount) { super(m, origin, fence, est, expectedModCount); } public KeySpliterator&lt;K,V&gt; trySplit() { int hi = getFence(), lo = index, mid = (lo + hi) &gt;&gt;&gt; 1; return (lo &gt;= mid || current != null) ? null : new KeySpliterator&lt;&gt;(map, lo, index = mid, est &gt;&gt;&gt;= 1, expectedModCount); } public void forEachRemaining(Consumer&lt;? super K&gt; action) { int i, hi, mc; if (action == null) throw new NullPointerException(); HashMap&lt;K,V&gt; m = map; Node&lt;K,V&gt;[] tab = m.table; if ((hi = fence) &lt; 0) { mc = expectedModCount = m.modCount; hi = fence = (tab == null) ? 0 : tab.length; } else mc = expectedModCount; if (tab != null &amp;&amp; tab.length &gt;= hi &amp;&amp; (i = index) &gt;= 0 &amp;&amp; (i &lt; (index = hi) || current != null)) { Node&lt;K,V&gt; p = current; current = null; do { if (p == null) p = tab[i++]; else { action.accept(p.key); p = p.next; } } while (p != null || i &lt; hi); if (m.modCount != mc) throw new ConcurrentModificationException(); } } public boolean tryAdvance(Consumer&lt;? super K&gt; action) { int hi; if (action == null) throw new NullPointerException(); Node&lt;K,V&gt;[] tab = map.table; if (tab != null &amp;&amp; tab.length &gt;= (hi = getFence()) &amp;&amp; index &gt;= 0) { while (current != null || index &lt; hi) { if (current == null) current = tab[index++]; else { K k = current.key; current = current.next; action.accept(k); if (map.modCount != expectedModCount) throw new ConcurrentModificationException(); return true; } } } return false; } public int characteristics() { return (fence &lt; 0 || est == map.size ? Spliterator.SIZED : 0) | Spliterator.DISTINCT; }} >folded ValueSpliterator分离器12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970static final class ValueSpliterator&lt;K,V&gt; extends HashMapSpliterator&lt;K,V&gt; implements Spliterator&lt;V&gt; { ValueSpliterator(HashMap&lt;K,V&gt; m, int origin, int fence, int est, int expectedModCount) { super(m, origin, fence, est, expectedModCount); } public ValueSpliterator&lt;K,V&gt; trySplit() { int hi = getFence(), lo = index, mid = (lo + hi) &gt;&gt;&gt; 1; return (lo &gt;= mid || current != null) ? null : new ValueSpliterator&lt;&gt;(map, lo, index = mid, est &gt;&gt;&gt;= 1, expectedModCount); } public void forEachRemaining(Consumer&lt;? super V&gt; action) { int i, hi, mc; if (action == null) throw new NullPointerException(); HashMap&lt;K,V&gt; m = map; Node&lt;K,V&gt;[] tab = m.table; if ((hi = fence) &lt; 0) { mc = expectedModCount = m.modCount; hi = fence = (tab == null) ? 0 : tab.length; } else mc = expectedModCount; if (tab != null &amp;&amp; tab.length &gt;= hi &amp;&amp; (i = index) &gt;= 0 &amp;&amp; (i &lt; (index = hi) || current != null)) { Node&lt;K,V&gt; p = current; current = null; do { if (p == null) p = tab[i++]; else { action.accept(p.value); p = p.next; } } while (p != null || i &lt; hi); if (m.modCount != mc) throw new ConcurrentModificationException(); } } public boolean tryAdvance(Consumer&lt;? super V&gt; action) { int hi; if (action == null) throw new NullPointerException(); Node&lt;K,V&gt;[] tab = map.table; if (tab != null &amp;&amp; tab.length &gt;= (hi = getFence()) &amp;&amp; index &gt;= 0) { while (current != null || index &lt; hi) { if (current == null) current = tab[index++]; else { V v = current.value; current = current.next; action.accept(v); if (map.modCount != expectedModCount) throw new ConcurrentModificationException(); return true; } } } return false; } public int characteristics() { return (fence &lt; 0 || est == map.size ? Spliterator.SIZED : 0); }} >folded EntrySpliterator分离器1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071static final class EntrySpliterator&lt;K,V&gt; extends HashMapSpliterator&lt;K,V&gt; implements Spliterator&lt;Map.Entry&lt;K,V&gt;&gt; { EntrySpliterator(HashMap&lt;K,V&gt; m, int origin, int fence, int est, int expectedModCount) { super(m, origin, fence, est, expectedModCount); } public EntrySpliterator&lt;K,V&gt; trySplit() { int hi = getFence(), lo = index, mid = (lo + hi) &gt;&gt;&gt; 1; return (lo &gt;= mid || current != null) ? null : new EntrySpliterator&lt;&gt;(map, lo, index = mid, est &gt;&gt;&gt;= 1, expectedModCount); } public void forEachRemaining(Consumer&lt;? super Map.Entry&lt;K,V&gt;&gt; action) { int i, hi, mc; if (action == null) throw new NullPointerException(); HashMap&lt;K,V&gt; m = map; Node&lt;K,V&gt;[] tab = m.table; if ((hi = fence) &lt; 0) { mc = expectedModCount = m.modCount; hi = fence = (tab == null) ? 0 : tab.length; } else mc = expectedModCount; if (tab != null &amp;&amp; tab.length &gt;= hi &amp;&amp; (i = index) &gt;= 0 &amp;&amp; (i &lt; (index = hi) || current != null)) { Node&lt;K,V&gt; p = current; current = null; do { if (p == null) p = tab[i++]; else { action.accept(p); p = p.next; } } while (p != null || i &lt; hi); if (m.modCount != mc) throw new ConcurrentModificationException(); } } public boolean tryAdvance(Consumer&lt;? super Map.Entry&lt;K,V&gt;&gt; action) { int hi; if (action == null) throw new NullPointerException(); Node&lt;K,V&gt;[] tab = map.table; if (tab != null &amp;&amp; tab.length &gt;= (hi = getFence()) &amp;&amp; index &gt;= 0) { while (current != null || index &lt; hi) { if (current == null) current = tab[index++]; else { Node&lt;K,V&gt; e = current; current = current.next; action.accept(e); if (map.modCount != expectedModCount) throw new ConcurrentModificationException(); return true; } } } return false; } public int characteristics() { return (fence &lt; 0 || est == map.size ? Spliterator.SIZED : 0) | Spliterator.DISTINCT; }} LinkedHashMap support LinkedHashMap支持>folded1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/* ------------------------------------------------------------ */// LinkedHashMap support/* * The following package-protected methods are designed to be * overridden by LinkedHashMap, but not by any other subclass. * Nearly all other internal methods are also package-protected * but are declared final, so can be used by LinkedHashMap, view * classes, and HashSet. * 下面的受程序包保护的方法旨在被LinkedHashMap覆盖，但不能被任何其他子类覆盖。 * 几乎所有其他内部方法也受程序包保护，但都声明为final，因此LinkedHashMap，视图类和HashSet可以使用它。 */// Create a regular (non-tree) node | 创建一个常规（非树）节点Node&lt;K,V&gt; newNode(int hash, K key, V value, Node&lt;K,V&gt; next) { return new Node&lt;&gt;(hash, key, value, next);}// For conversion from TreeNodes to plain nodes | 用于从TreeNodes转换为常规节点Node&lt;K,V&gt; replacementNode(Node&lt;K,V&gt; p, Node&lt;K,V&gt; next) { return new Node&lt;&gt;(p.hash, p.key, p.value, next);}// Create a tree bin node | 创建一个树节点TreeNode&lt;K,V&gt; newTreeNode(int hash, K key, V value, Node&lt;K,V&gt; next) { return new TreeNode&lt;&gt;(hash, key, value, next);}// For treeifyBin | 转化为树节点TreeNode&lt;K,V&gt; replacementTreeNode(Node&lt;K,V&gt; p, Node&lt;K,V&gt; next) { return new TreeNode&lt;&gt;(p.hash, p.key, p.value, next);}/** * Reset to initial default state. Called by clone and readObject. * 重置为初始默认状态。 由clone和readObject调用 */void reinitialize() { table = null; entrySet = null; keySet = null; values = null; modCount = 0; threshold = 0; size = 0;}// Callbacks to allow LinkedHashMap post-actions | 允许LinkedHashMap后处理的回调void afterNodeAccess(Node&lt;K,V&gt; p) { }void afterNodeInsertion(boolean evict) { }void afterNodeRemoval(Node&lt;K,V&gt; p) { }// Called only from writeObject, to ensure compatible ordering. | 仅从writeObject调用，以确保兼容的顺序。void internalWriteEntries(java.io.ObjectOutputStream s) throws IOException { Node&lt;K,V&gt;[] tab; if (size &gt; 0 &amp;&amp; (tab = table) != null) { for (int i = 0; i &lt; tab.length; ++i) { for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) { s.writeObject(e.key); s.writeObject(e.value); } } }} Tree bins 树箱>folded123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612/* ------------------------------------------------------------ */// Tree bins/** * Entry for Tree bins. Extends LinkedHashMap.Entry (which in turn * extends Node) so can be used as extension of either regular or * linked node. * 树箱的Entry。 继承LinkedHashMap.Entry（进而扩展Node），因此可以用作常规节点或链接节点的扩展。 */static final class TreeNode&lt;K,V&gt; extends LinkedHashMap.Entry&lt;K,V&gt; { TreeNode&lt;K,V&gt; parent; // red-black tree links TreeNode&lt;K,V&gt; left; TreeNode&lt;K,V&gt; right; TreeNode&lt;K,V&gt; prev; // needed to unlink next upon deletion boolean red; TreeNode(int hash, K key, V val, Node&lt;K,V&gt; next) { super(hash, key, val, next); } /** * Returns root of tree containing this node. * 返回包含此节点的树的根节点 */ final TreeNode&lt;K,V&gt; root() { for (TreeNode&lt;K,V&gt; r = this, p;;) { if ((p = r.parent) == null) return r; r = p; } } /** * Ensures that the given root is the first node of its bin. * 确保给定的根是其bin的第一个节点。 */ static &lt;K,V&gt; void moveRootToFront(Node&lt;K,V&gt;[] tab, TreeNode&lt;K,V&gt; root) { int n; if (root != null &amp;&amp; tab != null &amp;&amp; (n = tab.length) &gt; 0) { int index = (n - 1) &amp; root.hash; TreeNode&lt;K,V&gt; first = (TreeNode&lt;K,V&gt;)tab[index]; if (root != first) { Node&lt;K,V&gt; rn; tab[index] = root; TreeNode&lt;K,V&gt; rp = root.prev; if ((rn = root.next) != null) ((TreeNode&lt;K,V&gt;)rn).prev = rp; if (rp != null) rp.next = rn; if (first != null) first.prev = root; root.next = first; root.prev = null; } assert checkInvariants(root); } } /** * Finds the node starting at root p with the given hash and key. * The kc argument caches comparableClassFor(key) upon first use * comparing keys. * 根据给定的hash和key 从树根节点p开始查找该节点。 * kc参数在首次比较key时会缓存comparableClassFor(key) */ final TreeNode&lt;K,V&gt; find(int h, Object k, Class&lt;?&gt; kc) { TreeNode&lt;K,V&gt; p = this; do { int ph, dir; K pk; TreeNode&lt;K,V&gt; pl = p.left, pr = p.right, q; if ((ph = p.hash) &gt; h) p = pl; else if (ph &lt; h) p = pr; else if ((pk = p.key) == k || (k != null &amp;&amp; k.equals(pk))) return p; else if (pl == null) p = pr; else if (pr == null) p = pl; else if ((kc != null || (kc = comparableClassFor(k)) != null) &amp;&amp; (dir = compareComparables(kc, k, pk)) != 0) p = (dir &lt; 0) ? pl : pr; else if ((q = pr.find(h, k, kc)) != null) return q; else p = pl; } while (p != null); return null; } /** * Calls find for root node. * 调用查找根节点。 */ final TreeNode&lt;K,V&gt; getTreeNode(int h, Object k) { return ((parent != null) ? root() : this).find(h, k, null); } /** * Tie-breaking utility for ordering insertions when equal * hashCodes and non-comparable. We don't require a total * order, just a consistent insertion rule to maintain * equivalence across rebalancings. Tie-breaking further than * necessary simplifies testing a bit. * Tie-breaking程序，用于在hashCodes相等且不可比较时对插入进行排序。 * 我们不需要总的排序，只需一个一致的插入规则即可在重新平衡期间保持等效。 * Tie-breaking比简化测试更有必要。 */ static int tieBreakOrder(Object a, Object b) { int d; if (a == null || b == null || (d = a.getClass().getName(). compareTo(b.getClass().getName())) == 0) d = (System.identityHashCode(a) &lt;= System.identityHashCode(b) ? -1 : 1); return d; } /** * Forms tree of the nodes linked from this node. * 从该节点链接的节点的表单树。- 树化节点：非树节点 -&gt; 树节点 * @return root of tree */ final void treeify(Node&lt;K,V&gt;[] tab) { TreeNode&lt;K,V&gt; root = null; for (TreeNode&lt;K,V&gt; x = this, next; x != null; x = next) { next = (TreeNode&lt;K,V&gt;)x.next; x.left = x.right = null; if (root == null) { x.parent = null; x.red = false; root = x; } else { K k = x.key; int h = x.hash; Class&lt;?&gt; kc = null; for (TreeNode&lt;K,V&gt; p = root;;) { int dir, ph; K pk = p.key; if ((ph = p.hash) &gt; h) dir = -1; else if (ph &lt; h) dir = 1; else if ((kc == null &amp;&amp; (kc = comparableClassFor(k)) == null) || (dir = compareComparables(kc, k, pk)) == 0) dir = tieBreakOrder(k, pk); TreeNode&lt;K,V&gt; xp = p; if ((p = (dir &lt;= 0) ? p.left : p.right) == null) { x.parent = xp; if (dir &lt;= 0) xp.left = x; else xp.right = x; root = balanceInsertion(root, x); break; } } } } moveRootToFront(tab, root); } /** * Returns a list of non-TreeNodes replacing those linked from * this node. * 返回非TreeNode列表，该列表替换从该节点链接的非TreeNode。- 去树化：树节点 -&gt; 非树节点 */ final Node&lt;K,V&gt; untreeify(HashMap&lt;K,V&gt; map) { Node&lt;K,V&gt; hd = null, tl = null; for (Node&lt;K,V&gt; q = this; q != null; q = q.next) { Node&lt;K,V&gt; p = map.replacementNode(q, null); if (tl == null) hd = p; else tl.next = p; tl = p; } return hd; } /** * Tree version of putVal. */ final TreeNode&lt;K,V&gt; putTreeVal(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab, int h, K k, V v) { Class&lt;?&gt; kc = null; boolean searched = false; TreeNode&lt;K,V&gt; root = (parent != null) ? root() : this; for (TreeNode&lt;K,V&gt; p = root;;) { int dir, ph; K pk; if ((ph = p.hash) &gt; h) dir = -1; else if (ph &lt; h) dir = 1; else if ((pk = p.key) == k || (k != null &amp;&amp; k.equals(pk))) return p; else if ((kc == null &amp;&amp; (kc = comparableClassFor(k)) == null) || (dir = compareComparables(kc, k, pk)) == 0) { if (!searched) { TreeNode&lt;K,V&gt; q, ch; searched = true; if (((ch = p.left) != null &amp;&amp; (q = ch.find(h, k, kc)) != null) || ((ch = p.right) != null &amp;&amp; (q = ch.find(h, k, kc)) != null)) return q; } dir = tieBreakOrder(k, pk); } TreeNode&lt;K,V&gt; xp = p; if ((p = (dir &lt;= 0) ? p.left : p.right) == null) { Node&lt;K,V&gt; xpn = xp.next; TreeNode&lt;K,V&gt; x = map.newTreeNode(h, k, v, xpn); if (dir &lt;= 0) xp.left = x; else xp.right = x; xp.next = x; x.parent = x.prev = xp; if (xpn != null) ((TreeNode&lt;K,V&gt;)xpn).prev = x; moveRootToFront(tab, balanceInsertion(root, x)); return null; } } } /** * Removes the given node, that must be present before this call. * This is messier than typical red-black deletion code because we * cannot swap the contents of an interior node with a leaf * successor that is pinned by &quot;next&quot; pointers that are accessible * independently during traversal. So instead we swap the tree * linkages. If the current tree appears to have too few nodes, * the bin is converted back to a plain bin. (The test triggers * somewhere between 2 and 6 nodes, depending on tree structure). * 删除给定节点必须在此调用之前。 * 这比典型的红黑树删除代码更为混乱，因为我们不能将内部节点的内容与叶继承者交换，叶继承者是由在遍历期间可独立访问的“下一个”指针固定的。 * 因此，我们交换树链接。如果当前树的节点似乎太少，则将树箱转换回普通箱。 （该测试触发在2到6个节点之间的某个位置，具体取决于树的结构）。 */ final void removeTreeNode(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab, boolean movable) { int n; if (tab == null || (n = tab.length) == 0) return; int index = (n - 1) &amp; hash; TreeNode&lt;K,V&gt; first = (TreeNode&lt;K,V&gt;)tab[index], root = first, rl; TreeNode&lt;K,V&gt; succ = (TreeNode&lt;K,V&gt;)next, pred = prev; if (pred == null) tab[index] = first = succ; else pred.next = succ; if (succ != null) succ.prev = pred; if (first == null) return; if (root.parent != null) root = root.root(); if (root == null || root.right == null || (rl = root.left) == null || rl.left == null) { tab[index] = first.untreeify(map); // too small return; } TreeNode&lt;K,V&gt; p = this, pl = left, pr = right, replacement; if (pl != null &amp;&amp; pr != null) { TreeNode&lt;K,V&gt; s = pr, sl; while ((sl = s.left) != null) // find successor | 查找继任者 s = sl; boolean c = s.red; s.red = p.red; p.red = c; // swap colors | 交换颜色 TreeNode&lt;K,V&gt; sr = s.right; TreeNode&lt;K,V&gt; pp = p.parent; if (s == pr) { // p was s's direct parent | p是s的直接父级 p.parent = s; s.right = p; } else { TreeNode&lt;K,V&gt; sp = s.parent; if ((p.parent = sp) != null) { if (s == sp.left) sp.left = p; else sp.right = p; } if ((s.right = pr) != null) pr.parent = s; } p.left = null; if ((p.right = sr) != null) sr.parent = p; if ((s.left = pl) != null) pl.parent = s; if ((s.parent = pp) == null) root = s; else if (p == pp.left) pp.left = s; else pp.right = s; if (sr != null) replacement = sr; else replacement = p; } else if (pl != null) replacement = pl; else if (pr != null) replacement = pr; else replacement = p; if (replacement != p) { TreeNode&lt;K,V&gt; pp = replacement.parent = p.parent; if (pp == null) root = replacement; else if (p == pp.left) pp.left = replacement; else pp.right = replacement; p.left = p.right = p.parent = null; } TreeNode&lt;K,V&gt; r = p.red ? root : balanceDeletion(root, replacement); if (replacement == p) { // detach | 分离 TreeNode&lt;K,V&gt; pp = p.parent; p.parent = null; if (pp != null) { if (p == pp.left) pp.left = null; else if (p == pp.right) pp.right = null; } } if (movable) moveRootToFront(tab, r); } /** * Splits nodes in a tree bin into lower and upper tree bins, * or untreeifies if now too small. Called only from resize; * see above discussion about split bits and indices. * 将树箱中的节点拆分为较高和较低的树箱，如果现在太小，则取消树化。仅被resize调用； * 请参阅上面有关拆分位和索引的讨论。 * * @param map the map * @param tab the table for recording bin heads * @param index the index of the table being split * @param bit the bit of hash to split on */ final void split(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab, int index, int bit) { TreeNode&lt;K,V&gt; b = this; // Relink into lo and hi lists, preserving order | 重新链接到lo和hi列表，保留顺序 TreeNode&lt;K,V&gt; loHead = null, loTail = null; TreeNode&lt;K,V&gt; hiHead = null, hiTail = null; int lc = 0, hc = 0; for (TreeNode&lt;K,V&gt; e = b, next; e != null; e = next) { next = (TreeNode&lt;K,V&gt;)e.next; e.next = null; if ((e.hash &amp; bit) == 0) { if ((e.prev = loTail) == null) loHead = e; else loTail.next = e; loTail = e; ++lc; } else { if ((e.prev = hiTail) == null) hiHead = e; else hiTail.next = e; hiTail = e; ++hc; } } if (loHead != null) { if (lc &lt;= UNTREEIFY_THRESHOLD) tab[index] = loHead.untreeify(map); else { tab[index] = loHead; if (hiHead != null) // (else is already treeified) | 其他已经被树化了 loHead.treeify(tab); } } if (hiHead != null) { if (hc &lt;= UNTREEIFY_THRESHOLD) tab[index + bit] = hiHead.untreeify(map); else { tab[index + bit] = hiHead; if (loHead != null) hiHead.treeify(tab); } } } /* ------------------------------------------------------------ */ // Red-black tree methods, all adapted from CLR | 红黑树方法，全部改编自CLR static &lt;K,V&gt; TreeNode&lt;K,V&gt; rotateLeft(TreeNode&lt;K,V&gt; root, TreeNode&lt;K,V&gt; p) { TreeNode&lt;K,V&gt; r, pp, rl; if (p != null &amp;&amp; (r = p.right) != null) { if ((rl = p.right = r.left) != null) rl.parent = p; if ((pp = r.parent = p.parent) == null) (root = r).red = false; else if (pp.left == p) pp.left = r; else pp.right = r; r.left = p; p.parent = r; } return root; } static &lt;K,V&gt; TreeNode&lt;K,V&gt; rotateRight(TreeNode&lt;K,V&gt; root, TreeNode&lt;K,V&gt; p) { TreeNode&lt;K,V&gt; l, pp, lr; if (p != null &amp;&amp; (l = p.left) != null) { if ((lr = p.left = l.right) != null) lr.parent = p; if ((pp = l.parent = p.parent) == null) (root = l).red = false; else if (pp.right == p) pp.right = l; else pp.left = l; l.right = p; p.parent = l; } return root; } static &lt;K,V&gt; TreeNode&lt;K,V&gt; balanceInsertion(TreeNode&lt;K,V&gt; root, TreeNode&lt;K,V&gt; x) { x.red = true; for (TreeNode&lt;K,V&gt; xp, xpp, xppl, xppr;;) { if ((xp = x.parent) == null) { x.red = false; return x; } else if (!xp.red || (xpp = xp.parent) == null) return root; if (xp == (xppl = xpp.left)) { if ((xppr = xpp.right) != null &amp;&amp; xppr.red) { xppr.red = false; xp.red = false; xpp.red = true; x = xpp; } else { if (x == xp.right) { root = rotateLeft(root, x = xp); xpp = (xp = x.parent) == null ? null : xp.parent; } if (xp != null) { xp.red = false; if (xpp != null) { xpp.red = true; root = rotateRight(root, xpp); } } } } else { if (xppl != null &amp;&amp; xppl.red) { xppl.red = false; xp.red = false; xpp.red = true; x = xpp; } else { if (x == xp.left) { root = rotateRight(root, x = xp); xpp = (xp = x.parent) == null ? null : xp.parent; } if (xp != null) { xp.red = false; if (xpp != null) { xpp.red = true; root = rotateLeft(root, xpp); } } } } } } static &lt;K,V&gt; TreeNode&lt;K,V&gt; balanceDeletion(TreeNode&lt;K,V&gt; root, TreeNode&lt;K,V&gt; x) { for (TreeNode&lt;K,V&gt; xp, xpl, xpr;;) { if (x == null || x == root) return root; else if ((xp = x.parent) == null) { x.red = false; return x; } else if (x.red) { x.red = false; return root; } else if ((xpl = xp.left) == x) { if ((xpr = xp.right) != null &amp;&amp; xpr.red) { xpr.red = false; xp.red = true; root = rotateLeft(root, xp); xpr = (xp = x.parent) == null ? null : xp.right; } if (xpr == null) x = xp; else { TreeNode&lt;K,V&gt; sl = xpr.left, sr = xpr.right; if ((sr == null || !sr.red) &amp;&amp; (sl == null || !sl.red)) { xpr.red = true; x = xp; } else { if (sr == null || !sr.red) { if (sl != null) sl.red = false; xpr.red = true; root = rotateRight(root, xpr); xpr = (xp = x.parent) == null ? null : xp.right; } if (xpr != null) { xpr.red = (xp == null) ? false : xp.red; if ((sr = xpr.right) != null) sr.red = false; } if (xp != null) { xp.red = false; root = rotateLeft(root, xp); } x = root; } } } else { // symmetric | 对称的 if (xpl != null &amp;&amp; xpl.red) { xpl.red = false; xp.red = true; root = rotateRight(root, xp); xpl = (xp = x.parent) == null ? null : xp.left; } if (xpl == null) x = xp; else { TreeNode&lt;K,V&gt; sl = xpl.left, sr = xpl.right; if ((sl == null || !sl.red) &amp;&amp; (sr == null || !sr.red)) { xpl.red = true; x = xp; } else { if (sl == null || !sl.red) { if (sr != null) sr.red = false; xpl.red = true; root = rotateLeft(root, xpl); xpl = (xp = x.parent) == null ? null : xp.left; } if (xpl != null) { xpl.red = (xp == null) ? false : xp.red; if ((sl = xpl.left) != null) sl.red = false; } if (xp != null) { xp.red = false; root = rotateRight(root, xp); } x = root; } } } } } /** * Recursive invariant check * 递归不变检查 */ static &lt;K,V&gt; boolean checkInvariants(TreeNode&lt;K,V&gt; t) { TreeNode&lt;K,V&gt; tp = t.parent, tl = t.left, tr = t.right, tb = t.prev, tn = (TreeNode&lt;K,V&gt;)t.next; if (tb != null &amp;&amp; tb.next != t) return false; if (tn != null &amp;&amp; tn.prev != t) return false; if (tp != null &amp;&amp; t != tp.left &amp;&amp; t != tp.right) return false; if (tl != null &amp;&amp; (tl.parent != t || tl.hash &gt; t.hash)) return false; if (tr != null &amp;&amp; (tr.parent != t || tr.hash &lt; t.hash)) return false; if (t.red &amp;&amp; tl != null &amp;&amp; tl.red &amp;&amp; tr != null &amp;&amp; tr.red) return false; if (tl != null &amp;&amp; !checkInvariants(tl)) return false; if (tr != null &amp;&amp; !checkInvariants(tr)) return false; return true; }}","link":"/2020/10/15/source_code/lock/"},{"title":"TCP与UDP","text":"一、TCP与UDP简单介绍和对比1、TCP的概念 TCP（Transmission Control Protocol）传输控制协议TCP 是一种面向连接的，提供可靠交付服务和全双工通信的，基于字节流的端到端的传输层通信协议。 TCP在传输数据之前必须先建立连接，数据传输结束后要释放连接。 每一条TCP连接只能有2个端点，故TCP不提供广播或多播服务。 TCP提供可靠交付，通过TCP连接传输的数据，无差错、不丢失、不重复、并且按序到达。 TCP是面向字节流的。虽然应用进程和TCP的交互是一次一个数据块(大小不等），但TCP把应用程序交下来的数据看成仅仅是一连串的无结构的字节流。TCP并不知道所传输的字节流的含义。 2、UDP的概念 UDP（User Datagram Protocol）用户数据报协议UDP是一种无连接的，尽最大努力交付的，基于报文的端到端的传输层通信协议。 UDP，在发送数据之前不需要建立连接。 UDP不保证可靠交付，主机不需要位置复杂的连接状态。 UDP是面向报文的。UDP对应用层交下来的报文，既不合并，也不拆分，而是保留这些报文的的边界，即应用层交给UDP多长的报文，UDP就照样发送，即一次发送一个报文。在接收端，UDP一次交付一个完整的报文。 UDP没有拥塞控制，网络出现的拥塞不会使源主机的发送速率降低。 UDP支持一对一、一对多、多对一和多对多的交互通信。 UDP的首部开销小，只有8个字节，比TCP的20个字节的首部要短。 3、区别 TCP协议面向连接，UDP协议面向非连接。 TCP协议传输速度慢，UDP协议传输速度快。 TCP协议保证数据顺序，UDP协议不保证。 TCP协议保证数据正确性，UDP协议可能丢包。 TCP协议对系统资源要求多，UDP协议要求少。 4、使用情况 TCP协议适用于对效率要求相对低，但对准确性要求相对高的场景下，或者是有一种连接概念的场景下。 而UDP协议适用于对效率要求相对高，对准确性要求相对低的场景。 二、深入探究互联网本质1、网络协议及模型计算机与网络设备要相互通信，双方就必须基于相同的方法。比如，如何探测到通信目标、由哪一边先发起通信、使用哪种语言进行通信、怎样结束通信等规则都需要事先确定。不同的硬件、操作系统之间的通信，所有的这一切都需要一种规则。而我们就把这种规则称为协议（protocol）。网络协议有很多，按照功能不同，分工不同，人们人为的将其进行了分层，更便于理解。例如OSI七层模型，TCP/IP四层模型。实际上这个七层四层是不存在的，只是人为的划分的概念，区分出来的目的只是让你明白哪一层是干什么用的。 OSI：开放式系统互联通信参考模型（英语：Open System Interconnection Reference Model，缩写为 OSI），简称为 OSI 模型（OSI model），一种概念模型，由国际标准化组织提出，一个试图使各种计算机在世界范围内互连为网络的标准框架。定义于ISO/IEC 7498-1。 TCP/IP：（Transmission Control Protocol/Internet Protocol，传输控制协议/网际协议）是指能够在多个不同网络间实现信息传输的协议簇。 TCP、UDP、IP、FTP、HTTP、ICMP、SMTP 等都属于 TCP/IP 族内的协议， 只是因为在 TCP/IP 协议中 TCP 协议和 IP 协议最具代表性，所以被称为 TCP/IP 协议。这些协议可以划分为四层，分别为链路层、网络层、传输层和应用层。 2、TCP和UDP下图展示了分层模型： 如图所示，TCP/UDP都是传输层使用都协议","link":"/2020/10/01/computer_network/osi%E5%88%86%E5%B1%82%E8%AF%A6%E8%A7%A3/"}],"tags":[{"name":"test","slug":"test","link":"/tags/test/"},{"name":"jdk源码","slug":"jdk源码","link":"/tags/jdk%E6%BA%90%E7%A0%81/"},{"name":"TCP,UDP","slug":"TCP-UDP","link":"/tags/TCP-UDP/"},{"name":"TCP","slug":"TCP","link":"/tags/TCP/"},{"name":"UDP","slug":"UDP","link":"/tags/UDP/"}],"categories":[{"name":"test","slug":"test","link":"/categories/test/"},{"name":"jdk源码翻译","slug":"jdk源码翻译","link":"/categories/jdk%E6%BA%90%E7%A0%81%E7%BF%BB%E8%AF%91/"},{"name":"计算机网络","slug":"计算机网络","link":"/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]}